{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drax929/FED-CL/blob/main/FED_CL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tRIrM2fApXi",
        "outputId": "4bd7ebf1-2abd-4371-ea82-c35e854b5fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: flwr in /usr/local/lib/python3.12/dist-packages (1.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: click<8.2.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (8.1.8)\n",
            "Requirement already satisfied: cryptography<45.0.0,>=44.0.1 in /usr/local/lib/python3.12/dist-packages (from flwr) (44.0.3)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.12/dist-packages (from flwr) (1.75.0)\n",
            "Requirement already satisfied: grpcio-health-checking<2.0.0,>=1.62.3 in /usr/local/lib/python3.12/dist-packages (from flwr) (1.62.3)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr) (0.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from flwr) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.12/dist-packages (from flwr) (4.25.8)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (3.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr) (6.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (2.32.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from flwr) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.12/dist-packages (from flwr) (0.12.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr) (2.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.13.0,>=0.12.5->flwr) (1.5.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision flwr numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8dQIGZwDLpT",
        "outputId": "eb83d968-66f8-4998-f3b6-c100a41da22f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import math\n",
        "import copy\n",
        "import numpy as np\n",
        "from typing import Tuple, List, Dict, Any\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC50hhrIDU45"
      },
      "outputs": [],
      "source": [
        "class TwoCropTransform:\n",
        "    \"\"\"Return two strongly/weakly augmented views of an image for contrastive learning.\"\"\"\n",
        "    def __init__(self, base_transform):\n",
        "        self.base_transform = base_transform\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.base_transform(x), self.base_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWIMjXNODYR-"
      },
      "outputs": [],
      "source": [
        "class ContrastiveMNIST(Dataset):\n",
        "    \"\"\"Wrapper to provide two augmented views for MNIST.\"\"\"\n",
        "    def __init__(self, mnist_dataset, transform):\n",
        "        self.mnist_dataset = mnist_dataset\n",
        "        self.transform = transform  # TwoCropTransform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mnist_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.mnist_dataset[idx]\n",
        "        x1, x2 = self.transform(img)\n",
        "        return x1, x2, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIQqs5DeDbtt"
      },
      "outputs": [],
      "source": [
        "def partition_dirichlet(dataset: datasets.MNIST, num_clients: int, alpha: float=0.5, seed: int=0):\n",
        "    \"\"\"\n",
        "    Partition indices of dataset to num_clients with Dirichlet distribution per label.\n",
        "    Returns list of index lists for each client.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    labels = np.array(dataset.targets)\n",
        "    num_classes = len(np.unique(labels))\n",
        "    idx_by_class = [np.where(labels == c)[0] for c in range(num_classes)]\n",
        "\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idx_c = idx_by_class[c]\n",
        "        # draw proportions\n",
        "        proportions = np.random.dirichlet(alpha=[alpha]*num_clients)\n",
        "        # split idx_c according to proportions\n",
        "        proportions = (proportions / proportions.sum()) * len(idx_c)\n",
        "        proportions = np.round(proportions).astype(int)\n",
        "\n",
        "        # adjust rounding issues\n",
        "        while proportions.sum() > len(idx_c):\n",
        "            j = np.argmax(proportions)\n",
        "            proportions[j] -= 1\n",
        "        while proportions.sum() < len(idx_c):\n",
        "            j = np.argmin(proportions)\n",
        "            proportions[j] += 1\n",
        "\n",
        "        start = 0\n",
        "        for k in range(num_clients):\n",
        "            cnt = proportions[k]\n",
        "            if cnt > 0:\n",
        "                client_indices[k].extend(idx_c[start:start+cnt].tolist())\n",
        "                start += cnt\n",
        "\n",
        "    # ensure non-empty\n",
        "    for k in range(num_clients):\n",
        "        if len(client_indices[k]) == 0:\n",
        "            # assign a random sample\n",
        "            client_indices[k].append(np.random.choice(len(dataset)))\n",
        "    return client_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y2vnKQbDpSX"
      },
      "outputs": [],
      "source": [
        "class SmallConvEncoder(nn.Module):\n",
        "    def __init__(self, out_dim=128):\n",
        "        super().__init__()\n",
        "        # MNIST 1x28x28\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),  # 28x28\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),            # 14x14\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),            # 7x7\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*7*7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x0j9igvDtUd"
      },
      "outputs": [],
      "source": [
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, in_dim=128, hidden_dim=128, out_dim=64):\n",
        "        super().__init__()\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.head(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqFH_odkDw6o"
      },
      "outputs": [],
      "source": [
        "class NTXentLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.5, device='cpu'):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, z1, z2):\n",
        "        \"\"\"\n",
        "        z1, z2: tensors of shape (B, D) - projection outputs (not necessarily normalized)\n",
        "        \"\"\"\n",
        "        batch_size = z1.size(0)\n",
        "        z1 = F.normalize(z1, dim=1)\n",
        "        z2 = F.normalize(z2, dim=1)\n",
        "        representations = torch.cat([z1, z2], dim=0)  # 2B x D\n",
        "\n",
        "        # similarity matrix\n",
        "        sim = torch.matmul(representations, representations.T) / self.temperature  # 2B x 2B\n",
        "\n",
        "        # mask to remove similarity with itself\n",
        "        large_neg = -1e9\n",
        "        mask = (~torch.eye(2*batch_size, dtype=torch.bool)).to(self.device)\n",
        "        sim_masked = sim.masked_fill(~mask, large_neg)\n",
        "\n",
        "        # positives: i <-> i+B\n",
        "        labels = torch.arange(batch_size).to(self.device)\n",
        "        positives = torch.cat([torch.diag(sim, batch_size), torch.diag(sim, -batch_size)])  # len 2B?\n",
        "        # Simpler: compute logits and targets per original SimCLR implementation\n",
        "        logits = torch.cat([\n",
        "            torch.cat([sim[i, batch_size:batch_size+batch_size], sim[i, :batch_size]], dim=0).unsqueeze(0)\n",
        "            for i in range(batch_size)\n",
        "        ], dim=0)  # (B, 2B) -> but careful. For simplicity use a robust implementation below.\n",
        "\n",
        "        # We'll implement the standard approach: for each of the 2B examples, positives index is (i+batch_size) mod (2B)\n",
        "        logits_all = sim_masked  # (2B x 2B) with -inf on diag\n",
        "        labels_all = (torch.arange(2*batch_size) + batch_size) % (2*batch_size)\n",
        "        labels_all = labels_all.to(self.device)\n",
        "\n",
        "        loss = self.criterion(logits_all, labels_all)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EadQgCNtD0ie"
      },
      "outputs": [],
      "source": [
        "def nt_xent_loss(z1, z2, temperature=0.5):\n",
        "    \"\"\"Simple, robust NT-Xent for two augmented batches z1,z2 (B,D).\"\"\"\n",
        "    device = z1.device\n",
        "    B = z1.size(0)\n",
        "    z1 = F.normalize(z1, dim=1)\n",
        "    z2 = F.normalize(z2, dim=1)\n",
        "    z = torch.cat([z1, z2], dim=0)  # 2B x D\n",
        "    sim = torch.matmul(z, z.T) / temperature  # 2B x 2B\n",
        "    # mask out self-similarity\n",
        "    mask = (~torch.eye(2*B, dtype=torch.bool)).to(device)\n",
        "    sim_masked = sim.masked_select(mask).view(2*B, 2*B-1)\n",
        "\n",
        "    # positives: for i in [0..B-1], positive index is i+B and vice versa\n",
        "    positives = torch.cat([torch.diag(sim, B), torch.diag(sim, -B)], dim=0).unsqueeze(1)  # 2B x 1\n",
        "\n",
        "    # logits: concatenate positives and negatives\n",
        "    logits = torch.cat([positives, sim_masked], dim=1)\n",
        "    labels = torch.zeros(2*B, dtype=torch.long).to(device)\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKLasyMqD2_-"
      },
      "outputs": [],
      "source": [
        "class PrivCLClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model: nn.Module, proj: nn.Module, train_loader: DataLoader,\n",
        "                 device: torch.device, local_epochs: int = 1, lr=1e-3, tau=0.5):\n",
        "        self.device = device\n",
        "        self.model = model.to(self.device)\n",
        "        self.proj = proj.to(self.device)\n",
        "        self.train_loader = train_loader\n",
        "        self.local_epochs = local_epochs\n",
        "        self.lr = lr\n",
        "        self.tau = tau\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        # Return model + proj parameters as numpy arrays\n",
        "        params = []\n",
        "        for _, p in list(self.model.state_dict().items()) + list(self.proj.state_dict().items()):\n",
        "            params.append(p.cpu().numpy())\n",
        "        return params\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        # Parameters is a list of numpy arrays in same order\n",
        "        # Reconstruct state dicts\n",
        "        model_state = self.model.state_dict()\n",
        "        proj_state = self.proj.state_dict()\n",
        "        # Flatten keys\n",
        "        all_keys = list(model_state.keys()) + list(proj_state.keys())\n",
        "        assert len(parameters) == len(all_keys)\n",
        "        new_state = {}\n",
        "        i = 0\n",
        "        for k in model_state.keys():\n",
        "            new_state[k] = torch.tensor(parameters[i])\n",
        "            i += 1\n",
        "        self.model.load_state_dict(new_state, strict=False)\n",
        "        proj_state_new = {}\n",
        "        for k in proj_state.keys():\n",
        "            proj_state_new[k] = torch.tensor(parameters[i])\n",
        "            i += 1\n",
        "        self.proj.load_state_dict(proj_state_new, strict=False)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # set params\n",
        "        if parameters is not None:\n",
        "            self.set_parameters(parameters)\n",
        "\n",
        "        optimizer = optim.Adam(list(self.model.parameters()) + list(self.proj.parameters()), lr=self.lr)\n",
        "        device = self.device\n",
        "        self.model.train()\n",
        "        self.proj.train()\n",
        "        for epoch in range(self.local_epochs):\n",
        "            loop = tqdm(self.train_loader, desc=f\"Client local epoch {epoch+1}/{self.local_epochs}\", leave=False)\n",
        "            for x1, x2, _ in loop:\n",
        "                x1 = x1.to(device)\n",
        "                x2 = x2.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                h1 = self.model(x1)\n",
        "                h2 = self.model(x2)\n",
        "                z1 = self.proj(h1)\n",
        "                z2 = self.proj(h2)\n",
        "                loss = nt_xent_loss(z1, z2, temperature=self.tau)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        # return updated parameters\n",
        "        return self.get_parameters({}), len(self.train_loader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        # no server-side evaluation in baseline; return dummy loss and metrics\n",
        "        return float(0.0), len(self.train_loader.dataset), {\"accuracy\": 0.0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO1JNfOsD7W7"
      },
      "outputs": [],
      "source": [
        "def create_data_loaders(num_clients=5, alpha=0.5, batch_size=128):\n",
        "    # Download MNIST\n",
        "    base_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(28, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "    two_crop = TwoCropTransform(base_transform)\n",
        "    mnist_train = datasets.MNIST(\".\", train=True, download=True)\n",
        "    mnist_test = datasets.MNIST(\".\", train=False, download=True)\n",
        "\n",
        "    # Partition indices non-iid with dirichlet\n",
        "    client_idxs = partition_dirichlet(mnist_train, num_clients=num_clients, alpha=alpha, seed=42)\n",
        "\n",
        "    client_loaders = []\n",
        "    for k in range(num_clients):\n",
        "        subset = Subset(mnist_train, client_idxs[k])\n",
        "        wrapped = ContrastiveMNIST(subset, two_crop)\n",
        "        loader = DataLoader(wrapped, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0)\n",
        "        client_loaders.append(loader)\n",
        "\n",
        "    # a simple validation set (not used for FL training)\n",
        "    test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    test_wrapped = ContrastiveMNIST(mnist_test, TwoCropTransform(test_transform))\n",
        "    test_loader = DataLoader(test_wrapped, batch_size=batch_size, shuffle=False)\n",
        "    return client_loaders, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flwimzAxD_kL"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str, client_loaders, device, local_epochs):\n",
        "    \"\"\"Create a Flower client instance for the given client id (cid).\"\"\"\n",
        "    idx = int(cid)\n",
        "    model = SmallConvEncoder(out_dim=128)\n",
        "    proj = ProjectionHead(in_dim=128, hidden_dim=128, out_dim=64)\n",
        "    client = PrivCLClient(model=model, proj=proj, train_loader=client_loaders[idx],\n",
        "                          device=device, local_epochs=local_epochs, lr=1e-3, tau=0.5)\n",
        "    return client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTSjY-WJECAI"
      },
      "outputs": [],
      "source": [
        "def main_simulation(num_clients=5, rounds=10, local_epochs=1, batch_size=128, alpha=0.5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "    client_loaders, test_loader = create_data_loaders(num_clients=num_clients, alpha=alpha, batch_size=batch_size)\n",
        "\n",
        "    # Create a factory for clients\n",
        "    def _client_fn(cid: str):\n",
        "        return client_fn(cid, client_loaders, device=device, local_epochs=local_epochs)\n",
        "\n",
        "    # Start simulation (in-proc)\n",
        "    strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,  # use all clients each round (for simplicity)\n",
        "        min_fit_clients=num_clients,\n",
        "        min_available_clients=num_clients\n",
        "    )\n",
        "\n",
        "    print(f\"Starting simulation: {num_clients} clients, {rounds} rounds, local_epochs={local_epochs}\")\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=_client_fn,\n",
        "        num_clients=num_clients,\n",
        "        config=fl.server.ServerConfig(num_rounds=rounds),\n",
        "        strategy=strategy,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b5ba31b",
        "outputId": "82c869f0-64d0-46a3-be25-5631074f64d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr[simulation] in /usr/local/lib/python3.12/dist-packages (1.22.0)\n",
            "Requirement already satisfied: click<8.2.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (8.1.8)\n",
            "Requirement already satisfied: cryptography<45.0.0,>=44.0.1 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (44.0.3)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (1.75.0)\n",
            "Requirement already satisfied: grpcio-health-checking<2.0.0,>=1.62.3 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (1.62.3)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (0.0.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (2.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (4.25.8)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (3.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (6.0.2)\n",
            "Requirement already satisfied: ray==2.31.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (2.31.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (2.32.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (0.12.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (3.19.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (25.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (1.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio!=1.65.0,<2.0.0,>=1.62.3->flwr[simulation]) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation]) (0.1.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.27.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"flwr[simulation]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GQY0IwlEyw2",
        "outputId": "62fab9d7-ce8d-4104-bf0c-d58adcab44fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "WARNING:flwr:DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Starting simulation: 5 clients, 5 rounds, local_epochs=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "2025-09-28 16:43:10,048\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7947581031.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3973790515.0, 'node:__internal_head__': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=1428)\u001b[0m 2025-09-28 16:43:29.500647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=1428)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=1428)\u001b[0m E0000 00:00:1759077809.543161    1428 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=1428)\u001b[0m E0000 00:00:1759077809.549750    1428 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=1428)\u001b[0m W0000 00:00:1759077809.566705    1428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=1428)\u001b[0m W0000 00:00:1759077809.566750    1428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=1428)\u001b[0m W0000 00:00:1759077809.566754    1428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=1428)\u001b[0m W0000 00:00:1759077809.566757    1428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(pid=1427)\u001b[0m 2025-09-28 16:43:29.591758: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=1427)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=1427)\u001b[0m E0000 00:00:1759077809.623284    1427 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=1427)\u001b[0m E0000 00:00:1759077809.631240    1427 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=1427)\u001b[0m W0000 00:00:1759077809.651750    1427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/27 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   4%|▎         | 1/27 [00:00<00:25,  1.01it/s, loss=5.43]\n",
            "Client local epoch 1/1:   7%|▋         | 2/27 [00:01<00:17,  1.46it/s, loss=5.35]\n",
            "Client local epoch 1/1:  11%|█         | 3/27 [00:01<00:13,  1.76it/s, loss=4.91]\n",
            "Client local epoch 1/1:  15%|█▍        | 4/27 [00:02<00:11,  1.94it/s, loss=4.85]\n",
            "Client local epoch 1/1:  19%|█▊        | 5/27 [00:02<00:11,  1.99it/s, loss=4.72]\n",
            "Client local epoch 1/1:  22%|██▏       | 6/27 [00:03<00:10,  2.08it/s, loss=4.6]\n",
            "Client local epoch 1/1:  26%|██▌       | 7/27 [00:03<00:09,  2.13it/s, loss=4.49]\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "Client local epoch 1/1:  30%|██▉       | 8/27 [00:04<00:08,  2.14it/s, loss=4.46]\n",
            "Client local epoch 1/1:  33%|███▎      | 9/27 [00:04<00:08,  2.14it/s, loss=4.39]\n",
            "Client local epoch 1/1:  37%|███▋      | 10/27 [00:05<00:07,  2.19it/s, loss=4.37]\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/148 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/148 [00:00<01:20,  1.82it/s, loss=5.44]\n",
            "Client local epoch 1/1:   3%|▎         | 5/148 [00:02<01:08,  2.10it/s, loss=4.77]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  11%|█         | 16/148 [00:07<01:07,  1.97it/s, loss=4.37]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  93%|█████████▎| 25/27 [00:12<00:01,  1.80it/s, loss=4.17]\n",
            "Client local epoch 1/1:  96%|█████████▋| 26/27 [00:12<00:00,  1.65it/s, loss=4.2]\n",
            "                                                                                  \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/49 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   2%|▏         | 1/49 [00:00<00:21,  2.19it/s, loss=5.44]\n",
            "Client local epoch 1/1:  14%|█▍        | 7/49 [00:03<00:19,  2.21it/s, loss=4.5]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  25%|██▌       | 37/148 [00:17<00:48,  2.29it/s, loss=4.11]\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  57%|█████▋    | 28/49 [00:13<00:11,  1.82it/s, loss=4.14]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  39%|███▉      | 58/148 [00:28<00:51,  1.75it/s, loss=4.07]\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 45/49 [00:22<00:02,  1.80it/s, loss=4.06]\n",
            "Client local epoch 1/1:  94%|█████████▍| 46/49 [00:23<00:01,  1.82it/s, loss=4.05]\n",
            "Client local epoch 1/1:  96%|█████████▌| 47/49 [00:23<00:01,  1.70it/s, loss=4.06]\n",
            "Client local epoch 1/1:  98%|█████████▊| 48/49 [00:24<00:00,  1.66it/s, loss=4]\n",
            "Client local epoch 1/1:  45%|████▍     | 66/148 [00:33<00:50,  1.61it/s, loss=4.06]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "                                                                                  \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/95 [00:00<00:48,  1.94it/s, loss=5.45]\n",
            "Client local epoch 1/1:  52%|█████▏    | 77/148 [00:39<00:32,  2.21it/s, loss=3.98]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  22%|██▏       | 21/95 [00:09<00:33,  2.21it/s, loss=4.2]\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  32%|███▏      | 30/95 [00:14<00:35,  1.83it/s, loss=4.1]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  43%|████▎     | 41/95 [00:19<00:24,  2.20it/s, loss=4.1]\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  54%|█████▎    | 51/95 [00:24<00:26,  1.68it/s, loss=4]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  87%|████████▋ | 129/148 [01:04<00:08,  2.31it/s, loss=3.89]\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 136/148 [01:07<00:05,  2.29it/s, loss=3.91]\n",
            "Client local epoch 1/1:  93%|█████████▎| 137/148 [01:08<00:04,  2.27it/s, loss=3.89]\n",
            "Client local epoch 1/1:  93%|█████████▎| 138/148 [01:08<00:04,  2.28it/s, loss=3.87]\n",
            "Client local epoch 1/1:  94%|█████████▍| 139/148 [01:09<00:03,  2.30it/s, loss=3.88]\n",
            "Client local epoch 1/1:  95%|█████████▍| 140/148 [01:09<00:03,  2.27it/s, loss=3.88]\n",
            "Client local epoch 1/1:  78%|███████▊  | 74/95 [00:34<00:09,  2.31it/s, loss=3.94]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  95%|█████████▌| 141/148 [01:09<00:03,  2.28it/s, loss=3.87]\n",
            "Client local epoch 1/1:  96%|█████████▌| 142/148 [01:10<00:02,  2.17it/s, loss=3.87]\n",
            "Client local epoch 1/1:  97%|█████████▋| 143/148 [01:11<00:02,  1.96it/s, loss=3.86]\n",
            "Client local epoch 1/1:  97%|█████████▋| 144/148 [01:11<00:02,  1.79it/s, loss=3.86]\n",
            "Client local epoch 1/1:  98%|█████████▊| 145/148 [01:12<00:01,  1.82it/s, loss=3.86]\n",
            "Client local epoch 1/1:  99%|█████████▊| 146/148 [01:13<00:01,  1.66it/s, loss=3.87]\n",
            "Client local epoch 1/1:  99%|█████████▉| 147/148 [01:13<00:00,  1.77it/s, loss=3.86]\n",
            "                                                                                    \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/147 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/147 [00:00<01:05,  2.24it/s, loss=5.44]\n",
            "Client local epoch 1/1:  87%|████████▋ | 83/95 [00:40<00:06,  1.99it/s, loss=3.95]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 87/95 [00:41<00:03,  2.23it/s, loss=3.93]\n",
            "Client local epoch 1/1:  97%|█████████▋| 92/95 [00:43<00:01,  2.29it/s, loss=3.93]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:   9%|▉         | 13/147 [00:05<00:59,  2.24it/s, loss=4.38]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "                                                                                  \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  20%|█▉        | 29/147 [00:11<00:43,  2.69it/s, loss=4.16]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  31%|███▏      | 46/147 [00:16<00:32,  3.12it/s, loss=4.1]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  42%|████▏     | 62/147 [00:21<00:29,  2.85it/s, loss=4]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  53%|█████▎    | 78/147 [00:26<00:21,  3.16it/s, loss=3.94]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  65%|██████▍   | 95/147 [00:32<00:16,  3.23it/s, loss=3.97]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  75%|███████▍  | 110/147 [00:37<00:11,  3.16it/s, loss=3.91]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  86%|████████▋ | 127/147 [00:42<00:06,  3.25it/s, loss=3.89]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  91%|█████████ | 134/147 [00:44<00:04,  3.23it/s, loss=3.9]\n",
            "Client local epoch 1/1:  92%|█████████▏| 135/147 [00:44<00:03,  3.25it/s, loss=3.9]\n",
            "Client local epoch 1/1:  93%|█████████▎| 136/147 [00:45<00:03,  2.87it/s, loss=3.9]\n",
            "Client local epoch 1/1:  93%|█████████▎| 137/147 [00:45<00:03,  2.74it/s, loss=3.89]\n",
            "Client local epoch 1/1:  94%|█████████▍| 138/147 [00:46<00:03,  2.62it/s, loss=3.91]\n",
            "Client local epoch 1/1:  95%|█████████▍| 139/147 [00:46<00:03,  2.49it/s, loss=3.85]\n",
            "Client local epoch 1/1:  95%|█████████▌| 140/147 [00:47<00:02,  2.46it/s, loss=3.91]\n",
            "Client local epoch 1/1:  96%|█████████▌| 141/147 [00:47<00:02,  2.64it/s, loss=3.88]\n",
            "Client local epoch 1/1:  97%|█████████▋| 142/147 [00:47<00:01,  2.80it/s, loss=3.85]\n",
            "Client local epoch 1/1:  91%|█████████ | 134/147 [00:44<00:04,  3.23it/s, loss=3.9]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  97%|█████████▋| 143/147 [00:47<00:01,  2.89it/s, loss=3.87]\n",
            "Client local epoch 1/1:  98%|█████████▊| 144/147 [00:48<00:01,  2.96it/s, loss=3.87]\n",
            "Client local epoch 1/1:  99%|█████████▊| 145/147 [00:48<00:00,  3.03it/s, loss=3.91]\n",
            "Client local epoch 1/1:  99%|█████████▉| 146/147 [00:48<00:00,  3.12it/s, loss=3.86]\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
            "                                                                                    \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "Client local epoch 1/1:   0%|          | 0/49 [00:00<?, ?it/s]\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "Client local epoch 1/1:   2%|▏         | 1/49 [00:00<00:22,  2.10it/s, loss=4.24]\n",
            "Client local epoch 1/1:  14%|█▍        | 7/49 [00:03<00:18,  2.27it/s, loss=4.07]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:   0%|          | 0/147 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/147 [00:00<01:08,  2.15it/s, loss=4.29]\n",
            "Client local epoch 1/1:  12%|█▏        | 18/147 [00:08<01:18,  1.64it/s, loss=3.96]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  20%|█▉        | 29/147 [00:13<00:52,  2.24it/s, loss=3.91]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  28%|██▊       | 41/147 [00:19<00:46,  2.30it/s, loss=3.9]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 45/49 [00:21<00:02,  1.64it/s, loss=3.9]\n",
            "Client local epoch 1/1:  94%|█████████▍| 46/49 [00:22<00:01,  1.61it/s, loss=3.9]\n",
            "Client local epoch 1/1:  96%|█████████▌| 47/49 [00:22<00:01,  1.78it/s, loss=3.9]\n",
            "Client local epoch 1/1:  98%|█████████▊| 48/49 [00:23<00:00,  1.89it/s, loss=3.89]\n",
            "                                                                                  \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:  35%|███▍      | 51/147 [00:24<00:46,  2.07it/s, loss=3.89]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:   1%|          | 1/95 [00:00<00:45,  2.07it/s, loss=4.39]\n",
            "Client local epoch 1/1:  13%|█▎        | 12/95 [00:05<00:36,  2.28it/s, loss=4.02]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  23%|██▎       | 22/95 [00:10<00:44,  1.63it/s, loss=3.99]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  35%|███▍      | 33/95 [00:15<00:27,  2.22it/s, loss=3.93]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  47%|████▋     | 45/95 [00:21<00:21,  2.28it/s, loss=3.88]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  57%|█████▋    | 54/95 [00:26<00:20,  2.03it/s, loss=3.87]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  79%|███████▉  | 116/147 [00:55<00:14,  2.13it/s, loss=3.83]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  85%|████████▌ | 125/147 [01:00<00:13,  1.60it/s, loss=3.84]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  78%|███████▊  | 74/95 [00:37<00:13,  1.55it/s, loss=3.88]\n",
            "Client local epoch 1/1:  79%|███████▉  | 75/95 [00:37<00:12,  1.56it/s, loss=3.88]\n",
            "Client local epoch 1/1:  92%|█████████▏| 135/147 [01:05<00:05,  2.22it/s, loss=3.85]\n",
            "Client local epoch 1/1:  93%|█████████▎| 136/147 [01:05<00:04,  2.25it/s, loss=3.82]\n",
            "Client local epoch 1/1:  88%|████████▊ | 84/95 [00:41<00:05,  2.18it/s, loss=3.87]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  93%|█████████▎| 137/147 [01:05<00:04,  2.24it/s, loss=3.83]\n",
            "Client local epoch 1/1:  94%|█████████▍| 138/147 [01:06<00:03,  2.27it/s, loss=3.83]\n",
            "Client local epoch 1/1:  95%|█████████▍| 139/147 [01:06<00:03,  2.24it/s, loss=3.83]\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/27 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:  92%|█████████▏| 87/95 [00:42<00:03,  2.20it/s, loss=3.84]\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "Client local epoch 1/1:   4%|▎         | 1/27 [00:00<00:11,  2.22it/s, loss=4.22]\n",
            "                                                                                    \u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  91%|█████████ | 86/95 [00:42<00:04,  2.22it/s, loss=3.85]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/148 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/148 [00:00<01:14,  1.97it/s, loss=4.17]\n",
            "Client local epoch 1/1:   7%|▋         | 10/148 [00:05<01:02,  2.20it/s, loss=4.02]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  15%|█▍        | 22/148 [00:10<00:54,  2.33it/s, loss=3.95]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  93%|█████████▎| 25/27 [00:11<00:00,  2.27it/s, loss=3.97]\n",
            "Client local epoch 1/1:  96%|█████████▋| 26/27 [00:12<00:00,  2.24it/s, loss=3.95]\n",
            "                                                                                  \n",
            "Client local epoch 1/1:  24%|██▎       | 35/148 [00:15<00:41,  2.72it/s, loss=3.89]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  35%|███▌      | 52/148 [00:20<00:29,  3.31it/s, loss=3.87]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  47%|████▋     | 69/148 [00:25<00:28,  2.78it/s, loss=3.88]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  57%|█████▋    | 85/148 [00:31<00:18,  3.33it/s, loss=3.84]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  69%|██████▉   | 102/148 [00:36<00:13,  3.35it/s, loss=3.83]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  79%|███████▉  | 117/148 [00:41<00:09,  3.28it/s, loss=3.83]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  91%|█████████ | 134/148 [00:46<00:04,  3.27it/s, loss=3.83]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 136/148 [00:46<00:03,  3.32it/s, loss=3.82]\n",
            "Client local epoch 1/1:  93%|█████████▎| 137/148 [00:47<00:03,  3.32it/s, loss=3.82]\n",
            "Client local epoch 1/1:  93%|█████████▎| 138/148 [00:47<00:03,  3.27it/s, loss=3.81]\n",
            "Client local epoch 1/1:  94%|█████████▍| 139/148 [00:47<00:02,  3.29it/s, loss=3.82]\n",
            "Client local epoch 1/1:  95%|█████████▍| 140/148 [00:48<00:02,  3.32it/s, loss=3.8]\n",
            "Client local epoch 1/1:  95%|█████████▌| 141/148 [00:48<00:02,  3.31it/s, loss=3.83]\n",
            "Client local epoch 1/1:  96%|█████████▌| 142/148 [00:48<00:01,  3.29it/s, loss=3.85]\n",
            "Client local epoch 1/1:  97%|█████████▋| 143/148 [00:49<00:01,  3.29it/s, loss=3.81]\n",
            "Client local epoch 1/1:  97%|█████████▋| 144/148 [00:49<00:01,  2.96it/s, loss=3.81]\n",
            "Client local epoch 1/1:  98%|█████████▊| 145/148 [00:49<00:01,  2.80it/s, loss=3.81]\n",
            "Client local epoch 1/1:  99%|█████████▊| 146/148 [00:50<00:00,  2.70it/s, loss=3.84]\n",
            "Client local epoch 1/1:  99%|█████████▉| 147/148 [00:50<00:00,  2.55it/s, loss=3.82]\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
            "                                                                                    \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "Client local epoch 1/1:  91%|█████████ | 135/148 [00:46<00:03,  3.30it/s, loss=3.8]\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "Client local epoch 1/1:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "Client local epoch 1/1:   1%|          | 1/95 [00:00<00:43,  2.14it/s, loss=3.94]\n",
            "Client local epoch 1/1:   2%|▏         | 2/95 [00:00<00:43,  2.15it/s, loss=4.06]\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:   0%|          | 0/147 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/147 [00:00<01:10,  2.07it/s, loss=3.94]\n",
            "Client local epoch 1/1:  15%|█▍        | 14/95 [00:06<00:35,  2.30it/s, loss=3.88]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  16%|█▋        | 24/147 [00:11<01:16,  1.61it/s, loss=3.91]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  38%|███▊      | 36/95 [00:16<00:27,  2.17it/s, loss=3.88]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  49%|████▉     | 47/95 [00:21<00:22,  2.11it/s, loss=3.84]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  60%|██████    | 57/95 [00:27<00:17,  2.14it/s, loss=3.84]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  73%|███████▎  | 69/95 [00:32<00:11,  2.31it/s, loss=3.8]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  52%|█████▏    | 77/147 [00:37<00:42,  1.66it/s, loss=3.83]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 87/95 [00:41<00:03,  2.18it/s, loss=3.82]\n",
            "Client local epoch 1/1:  93%|█████████▎| 88/95 [00:41<00:03,  2.15it/s, loss=3.81]\n",
            "Client local epoch 1/1:  94%|█████████▎| 89/95 [00:42<00:02,  2.14it/s, loss=3.8]\n",
            "Client local epoch 1/1:  60%|█████▉    | 88/147 [00:42<00:27,  2.14it/s, loss=3.8]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  95%|█████████▍| 90/95 [00:42<00:02,  2.14it/s, loss=3.85]\n",
            "Client local epoch 1/1:  96%|█████████▌| 91/95 [00:43<00:01,  2.14it/s, loss=3.82]\n",
            "Client local epoch 1/1:  97%|█████████▋| 92/95 [00:43<00:01,  2.13it/s, loss=3.81]\n",
            "Client local epoch 1/1:  98%|█████████▊| 93/95 [00:44<00:00,  2.15it/s, loss=3.82]\n",
            "Client local epoch 1/1:  99%|█████████▉| 94/95 [00:44<00:00,  2.17it/s, loss=3.81]\n",
            "                                                                                  \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/27 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   4%|▎         | 1/27 [00:00<00:11,  2.30it/s, loss=4.02]\n",
            "Client local epoch 1/1:  67%|██████▋   | 99/147 [00:47<00:22,  2.13it/s, loss=3.8]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  56%|█████▌    | 15/27 [00:07<00:05,  2.05it/s, loss=3.9]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  93%|█████████▎| 25/27 [00:12<00:00,  2.13it/s, loss=3.88]\n",
            "Client local epoch 1/1:  96%|█████████▋| 26/27 [00:12<00:00,  2.15it/s, loss=3.88]\n",
            "Client local epoch 1/1:  80%|████████  | 118/147 [00:57<00:13,  2.16it/s, loss=3.81]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "                                                                                  \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/49 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   2%|▏         | 1/49 [00:00<00:21,  2.29it/s, loss=4.01]\n",
            "Client local epoch 1/1:  16%|█▋        | 8/49 [00:04<00:25,  1.60it/s, loss=3.93]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 135/147 [01:06<00:05,  2.13it/s, loss=3.83]\n",
            "Client local epoch 1/1:  93%|█████████▎| 136/147 [01:06<00:05,  2.20it/s, loss=3.81]\n",
            "Client local epoch 1/1:  93%|█████████▎| 137/147 [01:07<00:04,  2.24it/s, loss=3.8]\n",
            "Client local epoch 1/1:  94%|█████████▍| 138/147 [01:07<00:03,  2.25it/s, loss=3.8]\n",
            "Client local epoch 1/1:  95%|█████████▍| 139/147 [01:07<00:03,  2.30it/s, loss=3.8]\n",
            "Client local epoch 1/1:  95%|█████████▌| 140/147 [01:08<00:03,  2.31it/s, loss=3.8]\n",
            "Client local epoch 1/1:  41%|████      | 20/49 [00:09<00:12,  2.24it/s, loss=3.88]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  96%|█████████▌| 141/147 [01:08<00:02,  2.32it/s, loss=3.81]\n",
            "Client local epoch 1/1:  97%|█████████▋| 142/147 [01:09<00:02,  2.34it/s, loss=3.79]\n",
            "Client local epoch 1/1:  97%|█████████▋| 143/147 [01:09<00:01,  2.33it/s, loss=3.8]\n",
            "Client local epoch 1/1:  98%|█████████▊| 144/147 [01:10<00:01,  2.33it/s, loss=3.8]\n",
            "Client local epoch 1/1:  99%|█████████▊| 145/147 [01:10<00:00,  2.31it/s, loss=3.79]\n",
            "Client local epoch 1/1:  99%|█████████▉| 146/147 [01:10<00:00,  2.33it/s, loss=3.79]\n",
            "                                                                                   \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/148 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/148 [00:00<01:07,  2.17it/s, loss=3.98]\n",
            "Client local epoch 1/1:   3%|▎         | 5/148 [00:02<01:16,  1.87it/s, loss=3.93]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  10%|█         | 15/148 [00:07<00:57,  2.29it/s, loss=3.87]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 45/49 [00:21<00:01,  2.30it/s, loss=3.82]\n",
            "Client local epoch 1/1:  94%|█████████▍| 46/49 [00:22<00:01,  2.28it/s, loss=3.83]\n",
            "Client local epoch 1/1:  96%|█████████▌| 47/49 [00:22<00:00,  2.32it/s, loss=3.86]\n",
            "Client local epoch 1/1:  98%|█████████▊| 48/49 [00:22<00:00,  2.31it/s, loss=3.85]\n",
            "                                                                                  \n",
            "Client local epoch 1/1:  20%|█▉        | 29/148 [00:12<00:37,  3.19it/s, loss=3.84]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  29%|██▉       | 43/148 [00:18<00:44,  2.38it/s, loss=3.82]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  40%|███▉      | 59/148 [00:23<00:27,  3.25it/s, loss=3.81]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  50%|█████     | 74/148 [00:28<00:28,  2.63it/s, loss=3.86]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  61%|██████    | 90/148 [00:33<00:17,  3.23it/s, loss=3.82]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  72%|███████▏  | 107/148 [00:38<00:12,  3.23it/s, loss=3.81]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  82%|████████▏ | 122/148 [00:43<00:08,  3.14it/s, loss=3.78]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 136/148 [00:48<00:03,  3.33it/s, loss=3.81]\n",
            "Client local epoch 1/1:  93%|█████████▎| 137/148 [00:48<00:03,  3.31it/s, loss=3.79]\n",
            "Client local epoch 1/1:  93%|█████████▎| 138/148 [00:48<00:03,  3.31it/s, loss=3.81]\n",
            "Client local epoch 1/1:  94%|█████████▍| 139/148 [00:48<00:02,  3.29it/s, loss=3.8]\n",
            "Client local epoch 1/1:  91%|█████████ | 135/148 [00:47<00:03,  3.35it/s, loss=3.8]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  95%|█████████▍| 140/148 [00:49<00:02,  3.29it/s, loss=3.78]\n",
            "Client local epoch 1/1:  95%|█████████▌| 141/148 [00:49<00:02,  3.28it/s, loss=3.81]\n",
            "Client local epoch 1/1:  96%|█████████▌| 142/148 [00:49<00:01,  3.27it/s, loss=3.81]\n",
            "Client local epoch 1/1:  97%|█████████▋| 143/148 [00:50<00:01,  3.26it/s, loss=3.79]\n",
            "Client local epoch 1/1:  97%|█████████▋| 144/148 [00:50<00:01,  3.27it/s, loss=3.78]\n",
            "Client local epoch 1/1:  98%|█████████▊| 145/148 [00:50<00:00,  3.27it/s, loss=3.81]\n",
            "Client local epoch 1/1:  99%|█████████▊| 146/148 [00:51<00:00,  3.14it/s, loss=3.79]\n",
            "Client local epoch 1/1:  99%|█████████▉| 147/148 [00:51<00:00,  2.89it/s, loss=3.8]\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
            "                                                                                    \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "Client local epoch 1/1:   0%|          | 0/147 [00:00<?, ?it/s]\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "Client local epoch 1/1:   1%|          | 1/147 [00:00<01:25,  1.71it/s, loss=3.88]\n",
            "Client local epoch 1/1:   1%|▏         | 2/147 [00:01<01:22,  1.77it/s, loss=3.92]\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:   0%|          | 0/27 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   4%|▎         | 1/27 [00:00<00:17,  1.51it/s, loss=3.96]\n",
            "Client local epoch 1/1:   9%|▉         | 13/147 [00:06<01:02,  2.16it/s, loss=3.84]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  16%|█▋        | 24/147 [00:11<01:09,  1.77it/s, loss=3.86]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  93%|█████████▎| 25/27 [00:12<00:01,  1.72it/s, loss=3.86]\n",
            "Client local epoch 1/1:  96%|█████████▋| 26/27 [00:12<00:00,  1.61it/s, loss=3.85]\n",
            "                                                                                 \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/95 [00:00<00:46,  2.03it/s, loss=3.92]\n",
            "Client local epoch 1/1:  23%|██▎       | 34/147 [00:16<00:52,  2.17it/s, loss=3.83]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  31%|███       | 45/147 [00:21<00:46,  2.21it/s, loss=3.8]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  37%|███▋      | 54/147 [00:26<00:53,  1.72it/s, loss=3.83]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  39%|███▉      | 37/95 [00:17<00:26,  2.18it/s, loss=3.83]\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  51%|█████     | 48/95 [00:23<00:23,  2.02it/s, loss=3.83]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  59%|█████▊    | 86/147 [00:42<00:29,  2.04it/s, loss=3.81]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  66%|██████▌   | 97/147 [00:47<00:23,  2.12it/s, loss=3.81]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  72%|███████▏  | 106/147 [00:52<00:23,  1.73it/s, loss=3.82]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 87/95 [00:42<00:03,  2.23it/s, loss=3.79]\n",
            "Client local epoch 1/1:  93%|█████████▎| 88/95 [00:43<00:03,  2.22it/s, loss=3.78]\n",
            "Client local epoch 1/1:  94%|█████████▎| 89/95 [00:43<00:02,  2.21it/s, loss=3.8]\n",
            "Client local epoch 1/1:  80%|███████▉  | 117/147 [00:57<00:13,  2.21it/s, loss=3.8]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  95%|█████████▍| 90/95 [00:44<00:02,  2.15it/s, loss=3.82]\n",
            "Client local epoch 1/1:  96%|█████████▌| 91/95 [00:44<00:01,  2.15it/s, loss=3.8]\n",
            "Client local epoch 1/1:  97%|█████████▋| 92/95 [00:45<00:01,  2.16it/s, loss=3.81]\n",
            "Client local epoch 1/1:  98%|█████████▊| 93/95 [00:45<00:00,  2.18it/s, loss=3.8]\n",
            "Client local epoch 1/1:  99%|█████████▉| 94/95 [00:46<00:00,  2.21it/s, loss=3.79]\n",
            "                                                                                 \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/49 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   2%|▏         | 1/49 [00:00<00:25,  1.91it/s, loss=3.95]\n",
            "Client local epoch 1/1:   8%|▊         | 4/49 [00:02<00:27,  1.66it/s, loss=3.9]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 135/147 [01:06<00:06,  1.98it/s, loss=3.79]\n",
            "Client local epoch 1/1:  93%|█████████▎| 136/147 [01:07<00:05,  2.05it/s, loss=3.79]\n",
            "Client local epoch 1/1:  93%|█████████▎| 137/147 [01:07<00:04,  2.07it/s, loss=3.8]\n",
            "Client local epoch 1/1:  94%|█████████▍| 138/147 [01:08<00:04,  2.13it/s, loss=3.8]\n",
            "Client local epoch 1/1:  27%|██▋       | 13/49 [00:07<00:17,  2.12it/s, loss=3.88]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  95%|█████████▍| 139/147 [01:08<00:03,  2.12it/s, loss=3.79]\n",
            "Client local epoch 1/1:  95%|█████████▌| 140/147 [01:08<00:03,  2.18it/s, loss=3.78]\n",
            "Client local epoch 1/1:  96%|█████████▌| 141/147 [01:09<00:02,  2.21it/s, loss=3.77]\n",
            "Client local epoch 1/1:  97%|█████████▋| 142/147 [01:09<00:02,  2.20it/s, loss=3.79]\n",
            "Client local epoch 1/1:  97%|█████████▋| 143/147 [01:10<00:01,  2.24it/s, loss=3.83]\n",
            "Client local epoch 1/1:  98%|█████████▊| 144/147 [01:10<00:01,  2.24it/s, loss=3.78]\n",
            "Client local epoch 1/1:  99%|█████████▊| 145/147 [01:11<00:00,  2.27it/s, loss=3.82]\n",
            "Client local epoch 1/1:  99%|█████████▉| 146/147 [01:11<00:00,  2.21it/s, loss=3.78]\n",
            "                                                                                   \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/148 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/148 [00:00<01:13,  1.99it/s, loss=3.86]\n",
            "Client local epoch 1/1:  51%|█████     | 25/49 [00:12<00:11,  2.12it/s, loss=3.83]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:   7%|▋         | 11/148 [00:06<01:17,  1.76it/s, loss=3.82]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  15%|█▍        | 22/148 [00:11<00:59,  2.10it/s, loss=3.8]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 45/49 [00:22<00:01,  2.13it/s, loss=3.83]\n",
            "Client local epoch 1/1:  94%|█████████▍| 46/49 [00:23<00:01,  2.13it/s, loss=3.86]\n",
            "Client local epoch 1/1:  96%|█████████▌| 47/49 [00:23<00:00,  2.10it/s, loss=3.81]\n",
            "Client local epoch 1/1:  98%|█████████▊| 48/49 [00:24<00:00,  2.13it/s, loss=3.81]\n",
            "                                                                                  \n",
            "Client local epoch 1/1:  24%|██▍       | 36/148 [00:16<00:44,  2.54it/s, loss=3.81]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  35%|███▌      | 52/148 [00:21<00:30,  3.18it/s, loss=3.79]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  46%|████▌     | 68/148 [00:26<00:25,  3.18it/s, loss=3.79]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  56%|█████▌    | 83/148 [00:32<00:20,  3.21it/s, loss=3.77]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  68%|██████▊   | 100/148 [00:37<00:15,  3.17it/s, loss=3.78]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  78%|███████▊  | 115/148 [00:42<00:10,  3.04it/s, loss=3.79]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  89%|████████▉ | 132/148 [00:47<00:04,  3.22it/s, loss=3.79]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 136/148 [00:49<00:03,  3.23it/s, loss=3.77]\n",
            "Client local epoch 1/1:  93%|█████████▎| 137/148 [00:49<00:03,  3.18it/s, loss=3.81]\n",
            "Client local epoch 1/1:  93%|█████████▎| 138/148 [00:49<00:03,  3.18it/s, loss=3.78]\n",
            "Client local epoch 1/1:  94%|█████████▍| 139/148 [00:50<00:02,  3.17it/s, loss=3.77]\n",
            "Client local epoch 1/1:  95%|█████████▍| 140/148 [00:50<00:02,  3.18it/s, loss=3.77]\n",
            "Client local epoch 1/1:  95%|█████████▌| 141/148 [00:50<00:02,  3.18it/s, loss=3.77]\n",
            "Client local epoch 1/1:  96%|█████████▌| 142/148 [00:51<00:01,  3.20it/s, loss=3.77]\n",
            "Client local epoch 1/1:  97%|█████████▋| 143/148 [00:51<00:01,  3.13it/s, loss=3.8]\n",
            "Client local epoch 1/1:  97%|█████████▋| 144/148 [00:51<00:01,  2.83it/s, loss=3.76]\n",
            "Client local epoch 1/1:  98%|█████████▊| 145/148 [00:52<00:01,  2.69it/s, loss=3.76]\n",
            "Client local epoch 1/1:  99%|█████████▊| 146/148 [00:52<00:00,  2.54it/s, loss=3.77]\n",
            "Client local epoch 1/1:  99%|█████████▉| 147/148 [00:53<00:00,  2.44it/s, loss=3.76]\n",
            "Client local epoch 1/1:  91%|█████████ | 135/148 [00:48<00:04,  3.23it/s, loss=3.76]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "                                                                                    \n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "Client local epoch 1/1:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "Client local epoch 1/1:   1%|          | 1/95 [00:00<00:46,  2.00it/s, loss=3.85]\n",
            "Client local epoch 1/1:  18%|█▊        | 9/49 [00:04<00:18,  2.15it/s, loss=3.87]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:   0%|          | 0/49 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   2%|▏         | 1/49 [00:00<00:22,  2.09it/s, loss=3.88]\n",
            "Client local epoch 1/1:  41%|████      | 20/49 [00:09<00:15,  1.87it/s, loss=3.82]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  61%|██████    | 30/49 [00:14<00:08,  2.14it/s, loss=3.82]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  43%|████▎     | 41/95 [00:20<00:23,  2.30it/s, loss=3.79]\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 45/49 [00:21<00:01,  2.27it/s, loss=3.81]\n",
            "Client local epoch 1/1:  94%|█████████▍| 46/49 [00:21<00:01,  2.26it/s, loss=3.81]\n",
            "Client local epoch 1/1:  96%|█████████▌| 47/49 [00:22<00:00,  2.04it/s, loss=3.81]\n",
            "Client local epoch 1/1:  98%|█████████▊| 48/49 [00:23<00:00,  1.83it/s, loss=3.81]\n",
            "                                                                                  \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/27 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   4%|▎         | 1/27 [00:00<00:19,  1.36it/s, loss=3.96]\n",
            "Client local epoch 1/1:  52%|█████▏    | 49/95 [00:24<00:27,  1.66it/s, loss=3.8]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  44%|████▍     | 12/27 [00:06<00:07,  2.03it/s, loss=3.87]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  76%|███████▌  | 72/95 [00:36<00:13,  1.66it/s, loss=3.77]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  93%|█████████▎| 25/27 [00:13<00:01,  1.55it/s, loss=3.85]\n",
            "Client local epoch 1/1:  96%|█████████▋| 26/27 [00:13<00:00,  1.61it/s, loss=3.81]\n",
            "                                                                                  \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/147 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/147 [00:00<01:10,  2.08it/s, loss=3.87]\n",
            "Client local epoch 1/1:  86%|████████▋ | 82/95 [00:41<00:06,  2.16it/s, loss=3.78]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:   5%|▌         | 8/147 [00:04<01:02,  2.24it/s, loss=3.81]\n",
            "Client local epoch 1/1:   6%|▌         | 9/147 [00:04<01:00,  2.29it/s, loss=3.81]\n",
            "Client local epoch 1/1:  92%|█████████▏| 87/95 [00:43<00:03,  2.21it/s, loss=3.78]\n",
            "Client local epoch 1/1:  93%|█████████▎| 88/95 [00:44<00:03,  2.23it/s, loss=3.81]\n",
            "Client local epoch 1/1:  94%|█████████▎| 89/95 [00:44<00:02,  2.15it/s, loss=3.78]\n",
            "Client local epoch 1/1:  95%|█████████▍| 90/95 [00:45<00:02,  2.16it/s, loss=3.8]\n",
            "Client local epoch 1/1:  96%|█████████▌| 91/95 [00:45<00:01,  2.18it/s, loss=3.78]\n",
            "Client local epoch 1/1:  97%|█████████▋| 92/95 [00:46<00:01,  2.16it/s, loss=3.76]\n",
            "Client local epoch 1/1:  98%|█████████▊| 93/95 [00:46<00:00,  2.16it/s, loss=3.77]\n",
            "Client local epoch 1/1:  12%|█▏        | 17/147 [00:07<00:58,  2.21it/s, loss=3.81]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  99%|█████████▉| 94/95 [00:46<00:00,  2.15it/s, loss=3.77]\n",
            "                                                                                  \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "Client local epoch 1/1:   0%|          | 0/148 [00:00<?, ?it/s]\n",
            "Client local epoch 1/1:   1%|          | 1/148 [00:00<01:26,  1.70it/s, loss=3.8]\n",
            "Client local epoch 1/1:  18%|█▊        | 26/147 [00:12<01:05,  1.84it/s, loss=3.79]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  25%|██▌       | 37/147 [00:17<00:50,  2.20it/s, loss=3.81]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  32%|███▏      | 47/147 [00:22<00:57,  1.73it/s, loss=3.78]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  39%|███▉      | 57/147 [00:28<00:44,  2.03it/s, loss=3.79]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  46%|████▋     | 68/147 [00:33<00:36,  2.16it/s, loss=3.79]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  52%|█████▏    | 77/147 [00:38<00:40,  1.75it/s, loss=3.81]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  60%|█████▉    | 88/147 [00:43<00:28,  2.11it/s, loss=3.78]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  67%|██████▋   | 98/147 [00:49<00:29,  1.69it/s, loss=3.79]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  61%|██████    | 90/148 [00:45<00:26,  2.19it/s, loss=3.77]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  82%|████████▏ | 121/147 [00:59<00:11,  2.28it/s, loss=3.77]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  88%|████████▊ | 130/147 [01:04<00:08,  1.96it/s, loss=3.78]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  92%|█████████▏| 135/147 [01:07<00:05,  2.22it/s, loss=3.78]\n",
            "Client local epoch 1/1:  93%|█████████▎| 136/147 [01:07<00:04,  2.24it/s, loss=3.78]\n",
            "Client local epoch 1/1:  93%|█████████▎| 137/147 [01:07<00:04,  2.26it/s, loss=3.78]\n",
            "Client local epoch 1/1:  94%|█████████▍| 138/147 [01:08<00:04,  2.23it/s, loss=3.78]\n",
            "Client local epoch 1/1:  95%|█████████▍| 139/147 [01:08<00:03,  2.21it/s, loss=3.79]\n",
            "Client local epoch 1/1:  95%|█████████▌| 140/147 [01:09<00:03,  2.18it/s, loss=3.78]\n",
            "Client local epoch 1/1:  96%|█████████▌| 141/147 [01:09<00:02,  2.20it/s, loss=3.78]\n",
            "Client local epoch 1/1:  83%|████████▎ | 123/148 [01:01<00:10,  2.28it/s, loss=3.78]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  97%|█████████▋| 142/147 [01:10<00:02,  2.23it/s, loss=3.76]\n",
            "Client local epoch 1/1:  97%|█████████▋| 143/147 [01:10<00:01,  2.20it/s, loss=3.77]\n",
            "Client local epoch 1/1:  98%|█████████▊| 144/147 [01:11<00:01,  2.23it/s, loss=3.76]\n",
            "Client local epoch 1/1:  99%|█████████▊| 145/147 [01:11<00:00,  2.21it/s, loss=3.76]\n",
            "Client local epoch 1/1:  99%|█████████▉| 146/147 [01:11<00:00,  2.25it/s, loss=3.75]\n",
            "                                                                                    \n",
            "Client local epoch 1/1:  92%|█████████▏| 136/148 [01:06<00:04,  2.47it/s, loss=3.77]\n",
            "Client local epoch 1/1:  91%|█████████ | 135/148 [01:06<00:05,  2.53it/s, loss=3.77]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "Client local epoch 1/1:  93%|█████████▎| 137/148 [01:06<00:04,  2.48it/s, loss=3.76]\n",
            "Client local epoch 1/1:  93%|█████████▎| 138/148 [01:07<00:03,  2.66it/s, loss=3.77]\n",
            "Client local epoch 1/1:  94%|█████████▍| 139/148 [01:07<00:03,  2.85it/s, loss=3.77]\n",
            "Client local epoch 1/1:  95%|█████████▍| 140/148 [01:07<00:02,  2.97it/s, loss=3.76]\n",
            "Client local epoch 1/1:  95%|█████████▌| 141/148 [01:08<00:02,  3.01it/s, loss=3.77]\n",
            "Client local epoch 1/1:  96%|█████████▌| 142/148 [01:08<00:01,  3.02it/s, loss=3.77]\n",
            "Client local epoch 1/1:  97%|█████████▋| 143/148 [01:08<00:01,  3.10it/s, loss=3.75]\n",
            "Client local epoch 1/1:  97%|█████████▋| 144/148 [01:09<00:01,  3.11it/s, loss=3.76]\n",
            "Client local epoch 1/1:  98%|█████████▊| 145/148 [01:09<00:00,  3.16it/s, loss=3.76]\n",
            "Client local epoch 1/1:  99%|█████████▊| 146/148 [01:09<00:00,  3.21it/s, loss=3.77]\n",
            "Client local epoch 1/1:  99%|█████████▉| 147/148 [01:09<00:00,  3.19it/s, loss=3.76]\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
            "                                                                                    \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 620.16s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1428)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1427)\u001b[0m         \n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Example run\n",
        "    main_simulation(num_clients=5, rounds=5, local_epochs=1, batch_size=128, alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08_W0tDES4uw",
        "outputId": "966b3a4c-9006-4c75-f949-8e7619eca9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: flwr in /usr/local/lib/python3.12/dist-packages (1.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: click<8.2.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (8.1.8)\n",
            "Requirement already satisfied: cryptography<45.0.0,>=44.0.1 in /usr/local/lib/python3.12/dist-packages (from flwr) (44.0.3)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.12/dist-packages (from flwr) (1.75.0)\n",
            "Requirement already satisfied: grpcio-health-checking<2.0.0,>=1.62.3 in /usr/local/lib/python3.12/dist-packages (from flwr) (1.62.3)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr) (0.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from flwr) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.12/dist-packages (from flwr) (4.25.8)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (3.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr) (6.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (2.32.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from flwr) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from flwr) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.12/dist-packages (from flwr) (0.12.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr) (2.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.13.0,>=0.12.5->flwr) (1.5.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch flwr numpy tqdm networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQcUDMJoWn2s",
        "outputId": "f865b961-2328-4ac5-a5fb-8fde81d2fa92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.8.0 torchvision==0.19.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr1Gc3B-AgsC",
        "outputId": "644510be-73ae-42e7-fd84-87193dfefe34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.19.0%2Bcpu-cp312-cp312-linux_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio==2.8.0 in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch==2.8.0 and torchvision==0.19.0+cpu because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested torch==2.8.0\n",
            "    torchvision 0.19.0+cpu depends on torch==2.4.0\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.5.1+cpu.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxH20_PeBxNz",
        "outputId": "74c852d8-fa60-4543-ac02-f5b389c47e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.1+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcpu/torch_scatter-2.1.2%2Bpt25cpu-cp312-cp312-linux_x86_64.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.7/547.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcpu/torch_sparse-0.6.18%2Bpt25cpu-cp312-cp312-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcpu/torch_cluster-1.6.3%2Bpt25cpu-cp312-cp312-linux_x86_64.whl (792 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.1/792.1 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt25cpu-cp312-cp312-linux_x86_64.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.3/240.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt25cpu torch-scatter-2.1.2+pt25cpu torch-sparse-0.6.18+pt25cpu torch-spline-conv-1.2.2+pt25cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import flwr as fl\n",
        "\n",
        "import networkx as nx\n",
        "from torch_geometric.data import Data as PyGData\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool"
      ],
      "metadata": {
        "id": "bSJcsaX0B48M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fa6a73-2d7b-480b-d0d6-b9c34d17b22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def synth_graph(num_nodes=20, p=0.2, feat_dim=16, seed=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    G = nx.erdos_renyi_graph(num_nodes, p)\n",
        "    # add node features: random vectors\n",
        "    for n in G.nodes():\n",
        "        G.nodes[n]['x'] = np.random.randn(feat_dim).astype(np.float32)\n",
        "    pyg = from_networkx(G)\n",
        "    # from_networkx sets 'x' as attribute list; convert to tensor if needed\n",
        "    if hasattr(pyg, 'x') and pyg.x is None:\n",
        "        pyg.x = torch.randn((num_nodes, feat_dim), dtype=torch.float32)\n",
        "    return pyg"
      ],
      "metadata": {
        "id": "DJBCp1g8CBI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def synth_timeseries(length=200, freq=1.0, noise=0.1, phase=0.0, seed=None):\n",
        "    \"\"\"Generate synthetic 1D timeseries (sine + noise).\"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    t = np.arange(length)\n",
        "    series = np.sin(2 * math.pi * freq * (t / length) + phase) + noise * np.random.randn(length)\n",
        "    series = series.astype(np.float32)\n",
        "    return series"
      ],
      "metadata": {
        "id": "tZHDLVfjCGoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_client_synthetic_data(num_clients=5, graph_nodes=20, feat_dim=16, ts_len=200):\n",
        "    clients = []\n",
        "    for k in range(num_clients):\n",
        "        seed = 100 + k\n",
        "        p = 0.15 + 0.05 * (k % 3)  # vary density\n",
        "        graph = synth_graph(num_nodes=graph_nodes, p=p, feat_dim=feat_dim, seed=seed)\n",
        "        # timeseries parameters vary across clients\n",
        "        freq = 1.0 + 0.1 * (k % 4)\n",
        "        phase = 2.0 * math.pi * (k / max(1, num_clients))\n",
        "        noise = 0.05 + 0.05 * (k % 3)\n",
        "        ts = synth_timeseries(length=ts_len, freq=freq, noise=noise, phase=phase, seed=seed+1)\n",
        "        clients.append({'graph': graph, 'ts': ts})\n",
        "    return clients"
      ],
      "metadata": {
        "id": "YBHG0Fg2CJ_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_edge_dropout(data: PyGData, p_drop=0.2):\n",
        "    \"\"\"\n",
        "    Randomly drop edges with probability p_drop and return a new PyGData.\n",
        "    \"\"\"\n",
        "    edge_index = data.edge_index.clone()\n",
        "    E = edge_index.size(1)\n",
        "    mask = torch.rand(E) > p_drop\n",
        "    new_ei = edge_index[:, mask]\n",
        "    new_data = PyGData(x=data.x.clone(), edge_index=new_ei)\n",
        "    return new_data"
      ],
      "metadata": {
        "id": "OJ4bb0oZCNNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_feature_masking(data: PyGData, p_mask=0.1):\n",
        "    x = data.x.clone()\n",
        "    mask = (torch.rand(x.size()) > p_mask).float()\n",
        "    x = x * mask\n",
        "    return PyGData(x=x, edge_index=data.edge_index.clone())"
      ],
      "metadata": {
        "id": "_ccEC4-cCPqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ts_jitter(ts: np.ndarray, sigma=0.05):\n",
        "    return (ts + np.random.randn(*ts.shape) * sigma).astype(np.float32)"
      ],
      "metadata": {
        "id": "Bkc0pJrICT6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ts_scaling(ts: np.ndarray, sigma=0.1):\n",
        "    factor = np.random.normal(loc=1.0, scale=sigma)\n",
        "    return (ts * factor).astype(np.float32)"
      ],
      "metadata": {
        "id": "1qk59-PlCUwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ts_window(ts: np.ndarray, window_size=64, shift=None):\n",
        "    L = len(ts)\n",
        "    if shift is None:\n",
        "        start = np.random.randint(0, max(1, L - window_size + 1))\n",
        "    else:\n",
        "        start = shift\n",
        "    return ts[start:start+window_size].copy()"
      ],
      "metadata": {
        "id": "e4me3Pz-CX9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphEncoder(nn.Module):\n",
        "    def __init__(self, in_dim=16, hidden=64, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_dim, hidden)\n",
        "        self.conv2 = GCNConv(hidden, hidden)\n",
        "        self.lin = nn.Linear(hidden, out_dim)\n",
        "\n",
        "    def forward(self, data: PyGData):\n",
        "        x, edge_index, batch = data.x, data.edge_index, getattr(data, 'batch', None)\n",
        "        h = F.relu(self.conv1(x, edge_index))\n",
        "        h = F.relu(self.conv2(h, edge_index))\n",
        "        # graph-level embedding via mean pool (if batch not set, assume single graph)\n",
        "        if batch is None:\n",
        "            # single graph: compute mean over nodes\n",
        "            g = h.mean(dim=0, keepdim=True)  # 1 x hidden\n",
        "        else:\n",
        "            g = global_mean_pool(h, batch)  # B x hidden\n",
        "        z = self.lin(g)  # B x out_dim (or 1 x out_dim)\n",
        "        return z"
      ],
      "metadata": {
        "id": "vZ5i1e9HCY3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalEncoder(nn.Module):\n",
        "    def __init__(self, in_channels=1, hidden=64, out_dim=128, kernel_size=5):\n",
        "        super().__init__()\n",
        "        # simple 1D conv stack\n",
        "        self.conv1 = nn.Conv1d(in_channels, hidden, kernel_size=kernel_size, padding=kernel_size//2)\n",
        "        self.conv2 = nn.Conv1d(hidden, hidden, kernel_size=kernel_size, padding=kernel_size//2)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.lin = nn.Linear(hidden, out_dim)\n",
        "\n",
        "    def forward(self, ts_batch: torch.Tensor):\n",
        "        # ts_batch: (B, window_len) -> (B, 1, window_len)\n",
        "        x = ts_batch.unsqueeze(1)\n",
        "        h = F.relu(self.conv1(x))\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = self.pool(h).squeeze(-1)  # B x hidden\n",
        "        z = self.lin(h)  # B x out_dim\n",
        "        return z"
      ],
      "metadata": {
        "id": "hxJU5pi_CdGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FusionProjection(nn.Module):\n",
        "    def __init__(self, in_dim, proj_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, in_dim//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_dim//2, proj_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "OjjjyefFCgWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nt_xent_loss(z1, z2, temperature=0.5):\n",
        "    device = z1.device\n",
        "    B = z1.size(0)\n",
        "    z1 = F.normalize(z1, dim=1)\n",
        "    z2 = F.normalize(z2, dim=1)\n",
        "    z = torch.cat([z1, z2], dim=0)  # 2B x D\n",
        "    sim = torch.matmul(z, z.T) / temperature  # 2B x 2B\n",
        "    mask = (~torch.eye(2*B, dtype=torch.bool)).to(device)\n",
        "    sim_masked = sim.masked_select(mask).view(2*B, 2*B-1)\n",
        "    positives = torch.cat([torch.diag(sim, B), torch.diag(sim, -B)], dim=0).unsqueeze(1)\n",
        "    logits = torch.cat([positives, sim_masked], dim=1)\n",
        "    labels = torch.zeros(2*B, dtype=torch.long).to(device)\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "WYCDaVP_CjOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_info_loss(g1, g2, neg_g, margin=0.0):\n",
        "    # g1, g2: positive pooled graph embeddings (B x D), neg_g: negative graphs (B x D)\n",
        "    # maximize similarity between g1 and g2, minimize with neg_g\n",
        "    pos_sim = (F.normalize(g1, dim=1) * F.normalize(g2, dim=1)).sum(dim=1)\n",
        "    neg_sim = (F.normalize(g1, dim=1) * F.normalize(neg_g, dim=1)).sum(dim=1)\n",
        "    loss = - (pos_sim - neg_sim).mean()  # push pos up and neg down\n",
        "    return loss"
      ],
      "metadata": {
        "id": "MzeeTNMRCm8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def temporal_contrastive(z_anchor, z_pos, temperature=0.5):\n",
        "    return nt_xent_loss(z_anchor, z_pos, temperature=temperature)"
      ],
      "metadata": {
        "id": "Mv4WoPelCn7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultimodalPrivCLClient(fl.client.NumPyClient):\n",
        "    def __init__(self, graph_enc: nn.Module, temp_enc: nn.Module, fusion: nn.Module,\n",
        "                 client_data: dict, device: torch.device,\n",
        "                 local_steps:int=50, batch_size=16, window_size=64,\n",
        "                 lr=1e-3, weights=(1.0, 0.5, 0.5), tau=0.5):\n",
        "        \"\"\"\n",
        "        client_data: {'graph': PyGData, 'ts': numpy array}\n",
        "        weights: (w_fuse, w_graph, w_temp)\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "        self.graph_enc = graph_enc.to(device)\n",
        "        self.temp_enc = temp_enc.to(device)\n",
        "        self.fusion = fusion.to(device)\n",
        "        self.client_data = client_data\n",
        "        self.local_steps = local_steps\n",
        "        self.batch_size = batch_size\n",
        "        self.window_size = window_size\n",
        "        self.lr = lr\n",
        "        self.w_fuse, self.w_graph, self.w_temp = weights\n",
        "        self.tau = tau\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        params = []\n",
        "        for _, p in list(self.graph_enc.state_dict().items()) + list(self.temp_enc.state_dict().items()) + list(self.fusion.state_dict().items()):\n",
        "            params.append(p.cpu().numpy())\n",
        "        return params\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        # assign parameters in the same order\n",
        "        ge_state = self.graph_enc.state_dict()\n",
        "        te_state = self.temp_enc.state_dict()\n",
        "        fu_state = self.fusion.state_dict()\n",
        "        all_keys = list(ge_state.keys()) + list(te_state.keys()) + list(fu_state.keys())\n",
        "        assert len(parameters) == len(all_keys)\n",
        "        i = 0\n",
        "        new_ge = {}\n",
        "        for k in ge_state.keys():\n",
        "            new_ge[k] = torch.tensor(parameters[i])\n",
        "            i += 1\n",
        "        self.graph_enc.load_state_dict(new_ge, strict=False)\n",
        "        new_te = {}\n",
        "        for k in te_state.keys():\n",
        "            new_te[k] = torch.tensor(parameters[i])\n",
        "            i += 1\n",
        "        self.temp_enc.load_state_dict(new_te, strict=False)\n",
        "        new_fu = {}\n",
        "        for k in fu_state.keys():\n",
        "            new_fu[k] = torch.tensor(parameters[i])\n",
        "            i += 1\n",
        "        self.fusion.load_state_dict(new_fu, strict=False)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        if parameters is not None:\n",
        "            self.set_parameters(parameters)\n",
        "\n",
        "        opt = optim.Adam(list(self.graph_enc.parameters()) +\n",
        "                         list(self.temp_enc.parameters()) +\n",
        "                         list(self.fusion.parameters()), lr=self.lr)\n",
        "\n",
        "        self.graph_enc.train(); self.temp_enc.train(); self.fusion.train()\n",
        "        device = self.device\n",
        "\n",
        "        # For simplicity: treat each local step as a self-contained minibatch (since each client has 1 graph and 1 ts)\n",
        "        # We'll create B augmented pairs by repeating augmentations\n",
        "        for step in range(self.local_steps):\n",
        "            # Graph positive pair: two augmentations\n",
        "            g_orig = self.client_data['graph']\n",
        "            g_aug1 = graph_edge_dropout(g_orig, p_drop=0.2)\n",
        "            g_aug2 = graph_feature_masking(g_orig, p_mask=0.1)\n",
        "\n",
        "            # negative graph: corrupt by shuffling features\n",
        "            neg_x = g_orig.x[torch.randperm(g_orig.x.size(0))]\n",
        "            g_neg = PyGData(x=neg_x, edge_index=g_orig.edge_index.clone())\n",
        "\n",
        "            g_aug1 = g_aug1.to(device)\n",
        "            g_aug2 = g_aug2.to(device)\n",
        "            g_neg = g_neg.to(device)\n",
        "\n",
        "            # Temporal positive pair: two augmentations on windows\n",
        "            ts = self.client_data['ts']\n",
        "            w1 = ts_window(ts, self.window_size)\n",
        "            w2 = ts_jitter(ts_window(ts, self.window_size), sigma=0.05)\n",
        "            # cast to tensors\n",
        "            w1 = torch.tensor(w1, dtype=torch.float32).to(device)\n",
        "            w2 = torch.tensor(w2, dtype=torch.float32).to(device)\n",
        "\n",
        "            # Create a \"batch\" by duplicating (simple trick to get B>1)\n",
        "            B = self.batch_size\n",
        "            g_batch1 = PyGData(x=g_aug1.x.repeat(B,1) if g_aug1.x.dim()==2 else g_aug1.x, edge_index=g_aug1.edge_index)\n",
        "            g_batch2 = PyGData(x=g_aug2.x.repeat(B,1) if g_aug2.x.dim()==2 else g_aug2.x, edge_index=g_aug2.edge_index)\n",
        "            g_neg_batch = PyGData(x=g_neg.x.repeat(B,1) if g_neg.x.dim()==2 else g_neg.x, edge_index=g_neg.edge_index)\n",
        "            # NOTE: above repetition is a hacky way to emulate a batch of B identical graphs with same structure but it's okay for prototyping.\n",
        "\n",
        "            # graph embeddings (outputs shape: 1 x out_dim) -> expand to B x out_dim\n",
        "            ge1 = self.graph_enc(g_batch1).squeeze(0)  # out_dim\n",
        "            ge2 = self.graph_enc(g_batch2).squeeze(0)\n",
        "            gen = self.graph_enc(g_neg_batch).squeeze(0)\n",
        "            ge1_b = ge1.unsqueeze(0).repeat(B,1)\n",
        "            ge2_b = ge2.unsqueeze(0).repeat(B,1)\n",
        "            gen_b = gen.unsqueeze(0).repeat(B,1)\n",
        "\n",
        "            # temporal embeddings\n",
        "            # w1, w2 are (window_len,) -> create batch (B, window_len) by stacking jittered versions\n",
        "            w1_batch = torch.stack([torch.tensor(ts_jitter(w1.cpu().numpy(), sigma=0.02), dtype=torch.float32) for _ in range(B)]).to(device)\n",
        "            w2_batch = torch.stack([torch.tensor(ts_jitter(w2.cpu().numpy(), sigma=0.02), dtype=torch.float32) for _ in range(B)]).to(device)\n",
        "            te1 = self.temp_enc(w1_batch)  # B x out_dim\n",
        "            te2 = self.temp_enc(w2_batch)\n",
        "\n",
        "            # fuse (concatenate graph + temporal)\n",
        "            fused1 = torch.cat([ge1_b, te1], dim=1)  # B x (gdim + tdim)\n",
        "            fused2 = torch.cat([ge2_b, te2], dim=1)\n",
        "\n",
        "            # project\n",
        "            z1 = self.fusion(fused1)\n",
        "            z2 = self.fusion(fused2)\n",
        "\n",
        "            # losses\n",
        "            loss_fuse = nt_xent_loss(z1, z2, temperature=self.tau)\n",
        "            loss_graph = graph_info_loss(ge1_b, ge2_b, gen_b)\n",
        "            loss_temp = temporal_contrastive(te1, te2, temperature=self.tau)\n",
        "\n",
        "            loss = self.w_fuse * loss_fuse + self.w_graph * loss_graph + self.w_temp * loss_temp\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            if (step+1) % (max(1, self.local_steps//5)) == 0:\n",
        "                print(f\"[Client] step {step+1}/{self.local_steps} loss={loss.item():.4f} (fuse={loss_fuse.item():.4f}, g={loss_graph.item():.4f}, t={loss_temp.item():.4f})\")\n",
        "\n",
        "        return self.get_parameters({}), 1, {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        # Not implementing server-side eval here; return dummy\n",
        "        return float(0.0), 1, {\"accuracy\": 0.0}"
      ],
      "metadata": {
        "id": "iOWmKCpyCp-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_factory_fn(cid: str, client_synth_data, device, local_steps, batch_size, window_size):\n",
        "    idx = int(cid)\n",
        "    data = client_synth_data[idx]\n",
        "    # instantiate model parts\n",
        "    genc = GraphEncoder(in_dim=data['graph'].x.size(1), hidden=64, out_dim=128)\n",
        "    tempenc = TemporalEncoder(in_channels=1, hidden=64, out_dim=128)\n",
        "    fusion = FusionProjection(in_dim=128+128, proj_dim=128)\n",
        "    client = MultimodalPrivCLClient(graph_enc=genc, temp_enc=tempenc, fusion=fusion,\n",
        "                                    client_data=data, device=device,\n",
        "                                    local_steps=local_steps, batch_size=batch_size,\n",
        "                                    window_size=window_size, lr=1e-3, weights=(1.0,0.5,0.5), tau=0.5)\n",
        "    return client"
      ],
      "metadata": {
        "id": "V2bxIqmvCwQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_simulation(num_clients=5, rounds=5, local_steps=40):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "    client_data = create_client_synthetic_data(num_clients=num_clients, graph_nodes=20, feat_dim=16, ts_len=200)\n",
        "\n",
        "    def _client_fn(cid: str):\n",
        "        return client_factory_fn(cid, client_data, device=device, local_steps=local_steps, batch_size=16, window_size=64)\n",
        "\n",
        "    strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,\n",
        "        min_fit_clients=num_clients,\n",
        "        min_available_clients=num_clients\n",
        "    )\n",
        "    print(f\"Starting Phase 2 simulation: {num_clients} clients, {rounds} rounds\")\n",
        "    fl.simulation.start_simulation(client_fn=_client_fn, num_clients=num_clients,\n",
        "                                   config=fl.server.ServerConfig(num_rounds=rounds),\n",
        "                                   strategy=strategy)"
      ],
      "metadata": {
        "id": "4R4vgBPnCzeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start_simulation(num_clients=4, rounds=3, local_steps=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFXVhF2hC2jj",
        "outputId": "9c01738d-9e3c-4706-8327-665a84aa5cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/convert.py:278: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  data_dict[key] = torch.as_tensor(value)\n",
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=3, no round_timeout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Starting Phase 2 simulation: 4 clients, 3 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "2025-09-28 16:54:51,302\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7944292763.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3972146380.0, 'node:__internal_head__': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=4757)\u001b[0m 2025-09-28 16:55:11.994740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=4757)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=4757)\u001b[0m E0000 00:00:1759078512.023888    4757 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=4757)\u001b[0m E0000 00:00:1759078512.032483    4757 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=4757)\u001b[0m W0000 00:00:1759078512.054436    4757 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=4757)\u001b[0m W0000 00:00:1759078512.054496    4757 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=4757)\u001b[0m W0000 00:00:1759078512.054500    4757 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=4757)\u001b[0m W0000 00:00:1759078512.054503    4757 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m   warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m   warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m   warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
            "\u001b[36m(pid=4758)\u001b[0m 2025-09-28 16:55:11.994749: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=4758)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=4758)\u001b[0m E0000 00:00:1759078512.023880    4758 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=4758)\u001b[0m E0000 00:00:1759078512.032483    4758 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=4758)\u001b[0m W0000 00:00:1759078512.054503    4758 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 8/40 loss=5.2021 (fuse=3.4659, g=0.0009, t=3.4715)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 16/40 loss=5.1992 (fuse=3.4658, g=0.0009, t=3.4658)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 24/40 loss=5.1989 (fuse=3.4657, g=0.0004, t=3.4660)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 32/40 loss=5.1990 (fuse=3.4658, g=0.0006, t=3.4660)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 40/40 loss=5.1987 (fuse=3.4657, g=0.0003, t=3.4658)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 8/40 loss=5.1998 (fuse=3.4659, g=0.0015, t=3.4664)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 16/40 loss=5.1990 (fuse=3.4658, g=0.0007, t=3.4658)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 24/40 loss=5.1993 (fuse=3.4658, g=0.0008, t=3.4663)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 32/40 loss=5.1990 (fuse=3.4657, g=0.0003, t=3.4662)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 40/40 loss=5.1988 (fuse=3.4657, g=0.0004, t=3.4657)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 8/40 loss=5.1997 (fuse=3.4658, g=0.0013, t=3.4664)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 16/40 loss=5.1992 (fuse=3.4658, g=0.0010, t=3.4658)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 24/40 loss=5.1996 (fuse=3.4658, g=0.0004, t=3.4673)\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 32/40 loss=5.1997 (fuse=3.4658, g=0.0010, t=3.4668)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m   warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m   warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m   warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m [Client] step 40/40 loss=5.1989 (fuse=3.4657, g=0.0005, t=3.4658)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m [Client] step 8/40 loss=5.1999 (fuse=3.4659, g=0.0007, t=3.4674)\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m [Client] step 16/40 loss=5.2016 (fuse=3.4659, g=0.0015, t=3.4698)\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m [Client] step 24/40 loss=5.1989 (fuse=3.4658, g=0.0005, t=3.4657)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m [Client] step 32/40 loss=5.1995 (fuse=3.4658, g=0.0003, t=3.4672)\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m [Client] step 40/40 loss=5.1992 (fuse=3.4658, g=0.0004, t=3.4664)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m [Client] step 8/40 loss=5.1989 (fuse=3.4657, g=0.0004, t=3.4660)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m [Client] step 40/40 loss=5.1986 (fuse=3.4657, g=0.0000, t=3.4657)\u001b[32m [repeated 29x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 11.90s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "# Load Cora dataset\n",
        "dataset = Planetoid(root=\"data/Cora\", name=\"Cora\", transform=NormalizeFeatures())\n",
        "data = dataset[0]  # Single graph object\n",
        "\n",
        "print(\"Cora graph info:\")\n",
        "print(\"Nodes:\", data.num_nodes)\n",
        "print(\"Edges:\", data.num_edges)\n",
        "print(\"Features:\", data.num_node_features)\n",
        "print(\"Classes:\", dataset.num_classes)\n",
        "\n",
        "# Train/test splits\n",
        "X_train = data.x[data.train_mask]\n",
        "y_train = data.y[data.train_mask]\n",
        "\n",
        "X_val = data.x[data.val_mask]\n",
        "y_val = data.y[data.val_mask]\n",
        "\n",
        "X_test = data.x[data.test_mask]\n",
        "y_test = data.y[data.test_mask]\n",
        "\n",
        "print(\"Train nodes:\", X_train.shape, \" Val nodes:\", X_val.shape, \" Test nodes:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MagxhxZFHFAO",
        "outputId": "27c951a6-ca4a-4fd8-f2a6-be5cd1679564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=4757)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=4758)\u001b[0m         \n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cora graph info:\n",
            "Nodes: 2708\n",
            "Edges: 10556\n",
            "Features: 1433\n",
            "Classes: 7\n",
            "Train nodes: torch.Size([140, 1433])  Val nodes: torch.Size([500, 1433])  Test nodes: torch.Size([1000, 1433])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff169434",
        "outputId": "16e2016d-c555-4079-80a0-4233bd2543c3"
      },
      "source": [
        "!pip install tslearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tslearn\n",
            "  Downloading tslearn-0.6.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: scikit-learn<1.7,>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from tslearn) (1.6.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tslearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.17,>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from tslearn) (1.16.2)\n",
            "Requirement already satisfied: numba<0.62,>=0.58.1 in /usr/local/lib/python3.12/dist-packages (from tslearn) (0.60.0)\n",
            "Requirement already satisfied: joblib<1.6,>=0.12 in /usr/local/lib/python3.12/dist-packages (from tslearn) (1.5.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba<0.62,>=0.58.1->tslearn) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.7,>=1.3.2->tslearn) (3.6.0)\n",
            "Downloading tslearn-0.6.4-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tslearn\n",
            "Successfully installed tslearn-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tslearn.datasets import UCR_UEA_datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load ECG200 dataset\n",
        "ucr = UCR_UEA_datasets()\n",
        "loaded_data = ucr.load_dataset(\"ECG200\") # returns arrays; X shape (200, 96, 1) typically\n",
        "X, y = loaded_data[0], loaded_data[1] # Unpack only the data and labels\n",
        "\n",
        "print(\"ECG200 shape:\", X.shape, \"Labels:\", set(y))\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu9Ox3BmHG4g",
        "outputId": "938414c2-74a5-4887-d5b9-90be09dadc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECG200 shape: (100, 96, 1) Labels: {np.int64(1), np.int64(-1)}\n",
            "Train shape: (80, 96, 1)  Test shape: (20, 96, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "from tqdm import trange, tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# ---- Graph (PyG) imports ----\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.utils import dropout_adj\n",
        "from torch_geometric.nn import GCNConv"
      ],
      "metadata": {
        "id": "qvOMk5mGHnkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tslearn.datasets import UCR_UEA_datasets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "KY4jnNYtHtfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Krbjq1v9Hvxq",
        "outputId": "bdae79d8-b35d-4117-dff8-e0cb1460175d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRAPH_BATCH_NODES = 256   # number of node indices per contrastive batch (sampled from all nodes)\n",
        "GRAPH_LOCAL_EPOCHS = 20\n",
        "GRAPH_LR = 1e-3\n",
        "\n",
        "TS_BATCH = 64\n",
        "TS_EPOCHS = 30\n",
        "TS_LR = 1e-3\n",
        "TS_WINDOW = 96  # ECG200 length is 96\n",
        "\n",
        "TEMPERATURE = 0.5\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)"
      ],
      "metadata": {
        "id": "FE9PoLgqHyCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nt_xent_loss(z1: torch.Tensor, z2: torch.Tensor, temperature: float = 0.5) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    z1, z2: (B, D)\n",
        "    returns scalar loss\n",
        "    \"\"\"\n",
        "    device = z1.device\n",
        "    B = z1.size(0)\n",
        "    z1 = F.normalize(z1, dim=1)\n",
        "    z2 = F.normalize(z2, dim=1)\n",
        "    z = torch.cat([z1, z2], dim=0)  # 2B x D\n",
        "    sim = torch.matmul(z, z.T) / temperature  # 2B x 2B\n",
        "    # mask out self-similarity\n",
        "    mask = (~torch.eye(2*B, dtype=torch.bool)).to(device)\n",
        "    sim_masked = sim.masked_select(mask).view(2*B, 2*B-1)\n",
        "    positives = torch.cat([torch.diag(sim, B), torch.diag(sim, -B)], dim=0).unsqueeze(1)  # 2B x 1\n",
        "    logits = torch.cat([positives, sim_masked], dim=1)  # 2B x (2B)\n",
        "    labels = torch.zeros(2*B, dtype=torch.long).to(device)  # positives are at index 0\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "ABjmBOq0H0xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=128, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_dim, hidden)\n",
        "        self.conv2 = GCNConv(hidden, hidden)\n",
        "        self.proj = nn.Sequential(nn.Linear(hidden, hidden//2), nn.ReLU(), nn.Linear(hidden//2, out_dim))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        h = F.relu(self.conv1(x, edge_index))\n",
        "        h = F.relu(self.conv2(h, edge_index))  # N x hidden\n",
        "        z = self.proj(h)  # N x out_dim (node embeddings)\n",
        "        return z\n"
      ],
      "metadata": {
        "id": "BT2peToAH3kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_augment_edge_dropout(x, edge_index, drop_prob=0.2):\n",
        "    # drop edges using PyG's dropout_adj\n",
        "    new_ei, _ = dropout_adj(edge_index, p=drop_prob, force_undirected=True)\n",
        "    return x, new_ei"
      ],
      "metadata": {
        "id": "gqihuyg6H6lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_feat_mask(x, mask_prob=0.1):\n",
        "    x2 = x.clone()\n",
        "    mask = (torch.rand_like(x2) > mask_prob).float()\n",
        "    return x2 * mask"
      ],
      "metadata": {
        "id": "Kkqc-OmoH9d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_graph_contrastive(epochs=GRAPH_LOCAL_EPOCHS, batch_nodes=GRAPH_BATCH_NODES):\n",
        "    print(\"\\n--- Graph contrastive training (Cora) ---\")\n",
        "    dataset = Planetoid(root=\"data/Cora\", name=\"Cora\", transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(DEVICE)\n",
        "    N = data.num_nodes\n",
        "    feat_dim = data.num_node_features\n",
        "\n",
        "    enc = GraphEncoder(in_dim=feat_dim, hidden=256, out_dim=128).to(DEVICE)\n",
        "    opt = optim.Adam(enc.parameters(), lr=GRAPH_LR, weight_decay=1e-5)\n",
        "\n",
        "    node_indices = np.arange(N)\n",
        "\n",
        "    pbar = trange(epochs, desc=\"Graph epochs\")\n",
        "    for ep in pbar:\n",
        "        enc.train()\n",
        "        epoch_loss = 0.0\n",
        "        # iterate in mini-batches of node indices\n",
        "        np.random.shuffle(node_indices)\n",
        "        for i in range(0, N, batch_nodes):\n",
        "            batch_idx = node_indices[i: i+batch_nodes]\n",
        "            if len(batch_idx) == 0:\n",
        "                continue\n",
        "            # --- create two augmented graph views ---\n",
        "            # view 1: edge dropout + feat mask\n",
        "            x1 = data.x.clone()\n",
        "            x1 = graph_feat_mask(x1, mask_prob=0.1)\n",
        "            x1, ei1 = graph_augment_edge_dropout(x1, data.edge_index, drop_prob=0.2)\n",
        "            # view 2: different augmentations\n",
        "            x2 = data.x.clone()\n",
        "            x2 = graph_feat_mask(x2, mask_prob=0.15)\n",
        "            x2, ei2 = graph_augment_edge_dropout(x2, data.edge_index, drop_prob=0.25)\n",
        "\n",
        "            # compute node embeddings for all nodes (N x D)\n",
        "            with torch.no_grad():\n",
        "                # nothing\n",
        "                pass\n",
        "            z1_all = enc(x1.to(DEVICE), ei1.to(DEVICE))  # N x D\n",
        "            z2_all = enc(x2.to(DEVICE), ei2.to(DEVICE))  # N x D\n",
        "\n",
        "            # select batch rows\n",
        "            z1 = z1_all[batch_idx].to(DEVICE)  # b x D\n",
        "            z2 = z2_all[batch_idx].to(DEVICE)\n",
        "\n",
        "            # loss\n",
        "            loss = nt_xent_loss(z1, z2, temperature=TEMPERATURE)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            epoch_loss += float(loss.detach().cpu().item())\n",
        "\n",
        "        pbar.set_postfix({\"loss\": epoch_loss / max(1, math.ceil(N / batch_nodes))})\n",
        "    print(\"Graph training done. Encoder params ready.\")\n",
        "    return enc"
      ],
      "metadata": {
        "id": "VJX-ArKwIAxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalEncoder(nn.Module):\n",
        "    def __init__(self, window_len=TS_WINDOW, hidden=128, out_dim=128):\n",
        "        super().__init__()\n",
        "        # 1D conv stack\n",
        "        self.conv1 = nn.Conv1d(1, hidden, kernel_size=9, padding=4)\n",
        "        self.conv2 = nn.Conv1d(hidden, hidden, kernel_size=9, padding=4)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.proj = nn.Sequential(nn.Linear(hidden, hidden//2), nn.ReLU(), nn.Linear(hidden//2, out_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, window_len)\n",
        "        x = x.unsqueeze(1)  # B x 1 x L\n",
        "        h = F.relu(self.conv1(x))\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = self.pool(h).squeeze(-1)  # B x hidden\n",
        "        z = self.proj(h)  # B x out_dim\n",
        "        return z"
      ],
      "metadata": {
        "id": "e-cGhNnqIB9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ts_jitter(series: np.ndarray, sigma=0.03):\n",
        "    return (series + np.random.normal(0, sigma, size=series.shape)).astype(np.float32)\n",
        "\n",
        "def ts_scaling(series: np.ndarray, sigma=0.1):\n",
        "    factor = np.random.normal(1.0, sigma)\n",
        "    return (series * factor).astype(np.float32)\n",
        "\n",
        "def ts_window_slice(series: np.ndarray, window=TS_WINDOW):\n",
        "    L = series.shape[0]\n",
        "    if L == window:\n",
        "        return series.copy()\n",
        "    start = np.random.randint(0, L - window + 1)\n",
        "    return series[start:start+window].copy()"
      ],
      "metadata": {
        "id": "7Ww5uQSRIG71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TSContrastiveDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X_raw: np.ndarray):\n",
        "        # X_raw shape: (n_samples, length) or (n_samples, length, 1)\n",
        "        if X_raw.ndim == 3:\n",
        "            X_raw = X_raw.squeeze(-1)\n",
        "        self.X = X_raw.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.X[idx]\n",
        "        # create two augmented views\n",
        "        v1 = ts_jitter(ts_window_slice(s, window=TS_WINDOW), sigma=0.03)\n",
        "        v1 = ts_scaling(v1, sigma=0.05)\n",
        "        v2 = ts_jitter(ts_window_slice(s, window=TS_WINDOW), sigma=0.05)\n",
        "        v2 = ts_scaling(v2, sigma=0.08)\n",
        "        return v1, v2"
      ],
      "metadata": {
        "id": "zPgBwRqvIHvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ts_contrastive(epochs=TS_EPOCHS, batch_size=TS_BATCH):\n",
        "    print(\"\\n--- Time-series contrastive training (ECG200) ---\")\n",
        "    # Load ECG200\n",
        "    ucr = UCR_UEA_datasets()\n",
        "    loaded_data = ucr.load_dataset(\"ECG200\") # returns arrays; X shape (200, 96, 1) typically\n",
        "    X, y = loaded_data[0], loaded_data[1] # Unpack only the data and labels\n",
        "\n",
        "    # Flatten/truncate/reshape as needed\n",
        "    X = np.asarray(X)\n",
        "    if X.ndim == 3:\n",
        "        X = X.squeeze(-1)\n",
        "    # simple train/test split (we train on train set)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
        "    dataset = TSContrastiveDataset(X_train)\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0)\n",
        "\n",
        "    enc = TemporalEncoder(window_len=TS_WINDOW, hidden=128, out_dim=128).to(DEVICE)\n",
        "    opt = optim.Adam(enc.parameters(), lr=TS_LR, weight_decay=1e-5)\n",
        "\n",
        "    pbar = trange(epochs, desc=\"TS epochs\")\n",
        "    for ep in pbar:\n",
        "        enc.train()\n",
        "        epoch_loss = 0.0\n",
        "        for v1_np, v2_np in loader:\n",
        "            v1 = torch.tensor(v1_np).to(DEVICE)\n",
        "            v2 = torch.tensor(v2_np).to(DEVICE)\n",
        "            z1 = enc(v1)\n",
        "            z2 = enc(v2)\n",
        "            loss = nt_xent_loss(z1, z2, temperature=TEMPERATURE)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            epoch_loss += float(loss.detach().cpu().item())\n",
        "        pbar.set_postfix({\"loss\": epoch_loss / max(1, len(loader))})\n",
        "    print(\"Time-series training done.\")\n",
        "    return enc, (X_test, y_test)"
      ],
      "metadata": {
        "id": "958ZwIt2IMDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Train graph encoder\n",
        "    graph_encoder = train_graph_contrastive(epochs=GRAPH_LOCAL_EPOCHS, batch_nodes=GRAPH_BATCH_NODES)\n",
        "\n",
        "    # Train temporal encoder\n",
        "    ts_encoder, (X_test, y_test) = train_ts_contrastive(epochs=TS_EPOCHS, batch_size=TS_BATCH)\n",
        "\n",
        "    # Simple check: output embedding shapes\n",
        "    # Graph: test by running full graph through encoder\n",
        "    from torch_geometric.datasets import Planetoid\n",
        "    ds = Planetoid(root=\"data/Cora\", name=\"Cora\", transform=NormalizeFeatures())\n",
        "    d0 = ds[0].to(DEVICE)\n",
        "    graph_encoder.eval()\n",
        "    with torch.no_grad():\n",
        "        z_nodes = graph_encoder(d0.x, d0.edge_index)\n",
        "    print(\"Graph node embedding shape:\", z_nodes.shape)  # N x D\n",
        "\n",
        "    # TS: embed a small batch from test set\n",
        "    # X_test, y_test = ts_test # This unpacking is no longer needed here\n",
        "    sample = torch.tensor(X_test[:8], dtype=torch.float).to(DEVICE)\n",
        "    ts_encoder.eval()\n",
        "    with torch.no_grad():\n",
        "        z_ts = ts_encoder(sample)\n",
        "    print(\"TS embedding shape (8 samples):\", z_ts.shape)\n",
        "    print(\"\\nPhase 2 complete: trained encoders for graph and time-series.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plfvBN0bINEV",
        "outputId": "b81c469e-3448-4f36-bb43-3193b9a5d24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Graph contrastive training (Cora) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGraph epochs:   0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead\n",
            "  warnings.warn(out)\n",
            "Graph epochs: 100%|██████████| 20/20 [01:05<00:00,  3.26s/it, loss=4.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph training done. Encoder params ready.\n",
            "\n",
            "--- Time-series contrastive training (ECG200) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTS epochs:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/tmp/ipython-input-160758850.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  v1 = torch.tensor(v1_np).to(DEVICE)\n",
            "/tmp/ipython-input-160758850.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  v2 = torch.tensor(v2_np).to(DEVICE)\n",
            "TS epochs: 100%|██████████| 30/30 [00:05<00:00,  5.81it/s, loss=3.99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time-series training done.\n",
            "Graph node embedding shape: torch.Size([2708, 128])\n",
            "TS embedding shape (8 samples): torch.Size([8, 128])\n",
            "\n",
            "Phase 2 complete: trained encoders for graph and time-series.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "XEO3N_XeASID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FusionProjection(nn.Module):\n",
        "    def __init__(self, in_dim, proj_dim=128):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(in_dim, in_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_dim // 2, proj_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)"
      ],
      "metadata": {
        "id": "XKrk7XUgAVB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultimodalEncoder(nn.Module):\n",
        "    def __init__(self, graph_in_dim, ts_window_len,\n",
        "                 hidden_dim=128, out_dim=128, fusion_dim=128):\n",
        "        super().__init__()\n",
        "        # Individual encoders\n",
        "        self.graph_enc = GraphEncoder(in_dim=graph_in_dim,\n",
        "                                      hidden=hidden_dim, out_dim=out_dim)\n",
        "        self.ts_enc = TemporalEncoder(window_len=ts_window_len,\n",
        "                                      hidden=hidden_dim, out_dim=out_dim)\n",
        "        # Fusion projection\n",
        "        self.fusion = FusionProjection(in_dim=out_dim*2, proj_dim=fusion_dim)\n",
        "\n",
        "    def forward(self, x_graph, edge_index, x_ts):\n",
        "        # Encode graph and time-series separately\n",
        "        z_g = self.graph_enc(x_graph, edge_index)  # shape: N x out_dim\n",
        "        z_t = self.ts_enc(x_ts)                    # shape: B x out_dim\n",
        "\n",
        "        # NOTE: For simplicity, align batch sizes (e.g., sample B nodes = B ts samples)\n",
        "        fused = torch.cat([z_g, z_t], dim=1)       # shape: B x (2*out_dim)\n",
        "        z_f = self.fusion(fused)                   # shape: B x fusion_dim\n",
        "        return z_f"
      ],
      "metadata": {
        "id": "ldAgL6gaAYuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_multimodal_contrastive(model, graph_data, ts_loader, optimizer, epochs=10, temperature=0.5):\n",
        "    device = next(model.parameters()).device\n",
        "    model.train()\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for (ts1, ts2) in ts_loader:  # two augmented time-series views\n",
        "            ts1, ts2 = ts1.to(device), ts2.to(device)\n",
        "            # Graph augmentations\n",
        "            x1 = graph_feat_mask(graph_data.x.clone(), mask_prob=0.1)\n",
        "            x1, ei1 = graph_augment_edge_dropout(x1, graph_data.edge_index, drop_prob=0.2)\n",
        "            x2 = graph_feat_mask(graph_data.x.clone(), mask_prob=0.15)\n",
        "            x2, ei2 = graph_augment_edge_dropout(x2, graph_data.edge_index, drop_prob=0.25)\n",
        "\n",
        "            # Forward pass: fused embeddings\n",
        "            z1 = model(x1.to(device), ei1.to(device), ts1)  # fused view 1\n",
        "            z2 = model(x2.to(device), ei2.to(device), ts2)  # fused view 2\n",
        "\n",
        "            # Contrastive loss\n",
        "            loss = nt_xent_loss(z1, z2, temperature=temperature)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {ep+1}/{epochs}, Loss={total_loss/len(ts_loader):.4f}\")"
      ],
      "metadata": {
        "id": "YkGHeLpeAdJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opacus\n",
        "from opacus import PrivacyEngine\n",
        "from scipy.stats import entropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjurvV0JA_Cl",
        "outputId": "2580d3d5-b7ef-4d3c-e11f-8d67f0536f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-1.5.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.8.0+cu126)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.12/dist-packages (from opacus) (1.16.2)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n",
            "Downloading opacus-1.5.4-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opacus\n",
            "Successfully installed opacus-1.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from opacus import PrivacyEngine\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "import flwr as fl\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "TtDOWYUeKCRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _hist_entropy(tensor, bins=64):\n",
        "    arr = tensor.detach().cpu().float().view(-1).numpy()\n",
        "    if arr.size == 0:\n",
        "        return 0.0\n",
        "    hist, _ = np.histogram(arr, bins=bins, density=True)\n",
        "    hist = hist + 1e-12\n",
        "    hist = hist / hist.sum()\n",
        "    return float(-np.sum(hist * np.log(hist)))"
      ],
      "metadata": {
        "id": "asF5U-1yMSIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adaptive_noise_from_entropy(entropy_val, base=1.0, min_noise=0.5, max_noise=3.0):\n",
        "    noise = base / (1.0 + entropy_val)\n",
        "    noise = max(min_noise, min(noise, max_noise))\n",
        "    return float(noise)"
      ],
      "metadata": {
        "id": "ifopNN5fMVEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noise_for_image_batch(image_batch, base=1.0):\n",
        "    return adaptive_noise_from_entropy(_hist_entropy(image_batch), base=base)"
      ],
      "metadata": {
        "id": "NXpLXdHzMYCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noise_for_graph(graph_data, node_idx=None, base=1.0):\n",
        "    x = graph_data.x if node_idx is None else graph_data.x[node_idx]\n",
        "    return adaptive_noise_from_entropy(_hist_entropy(x), base=base)"
      ],
      "metadata": {
        "id": "EWC1b-MAMcbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noise_for_ts_batch(ts_batch, base=1.0):\n",
        "    return adaptive_noise_from_entropy(_hist_entropy(ts_batch), base=base)"
      ],
      "metadata": {
        "id": "f4-jbqJtMgPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_noise(n_img=None, n_graph=None, n_ts=None, strategy=\"max\", weights=(1.0,1.0,1.0)):\n",
        "    vals = [v for v in (n_img, n_graph, n_ts) if v is not None]\n",
        "    if not vals:\n",
        "        return 1.0\n",
        "    if strategy == \"max\":\n",
        "        return float(max(vals))\n",
        "    if strategy == \"weighted\":\n",
        "        w = np.array(weights)[:len(vals)]\n",
        "        w = w / w.sum()\n",
        "        return float((w * np.array(vals)).sum())\n",
        "    return float(max(vals))"
      ],
      "metadata": {
        "id": "bGmP5dtXMi8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultimodalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Given:\n",
        "      - graph_data: PyG Data (graph.x, graph.edge_index), used only for node features.\n",
        "      - ts_windows: torch.Tensor shape (N_ts, L)\n",
        "      - optional image tensor images: (N_img, C, H, W)\n",
        "    This simple dataset samples indices 0..N-1 and yields tuples (img, node_idx, ts_window)\n",
        "    For real data you should align or sample properly per-client.\n",
        "    \"\"\"\n",
        "    def __init__(self, graph_data=None, ts_windows=None, images=None, N=None):\n",
        "        self.graph = graph_data\n",
        "        self.ts = ts_windows\n",
        "        self.images = images\n",
        "        # choose effective length\n",
        "        candidates = []\n",
        "        if ts_windows is not None:\n",
        "            candidates.append(ts_windows.shape[0])\n",
        "        if images is not None:\n",
        "            candidates.append(images.shape[0])\n",
        "        if graph_data is not None:\n",
        "            candidates.append(graph_data.x.shape[0])\n",
        "        self.N = N if N is not None else (min(candidates) if candidates else 0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.N\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx % self.images.shape[0]] if self.images is not None else torch.zeros(1)\n",
        "        node_idx = idx % self.graph.x.size(0) if self.graph is not None else 0\n",
        "        ts = self.ts[idx % self.ts.shape[0]] if self.ts is not None else torch.zeros(10)\n",
        "        return img, node_idx, ts"
      ],
      "metadata": {
        "id": "Cpb1tRuvMks4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(in_dim, out_dim)\n",
        "    def forward(self, x, edge_index=None):\n",
        "        return self.lin(x)"
      ],
      "metadata": {
        "id": "Jj8hzINNNC1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalEncoder(nn.Module):\n",
        "    def __init__(self, L, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(nn.Conv1d(1,64,9,padding=4), nn.ReLU(), nn.AdaptiveAvgPool1d(1), nn.Flatten(), nn.Linear(64, out_dim))\n",
        "    def forward(self, x):\n",
        "        if x.dim()==2: x = x.unsqueeze(1)  # (B,1,L)\n",
        "        return self.conv(x)\n",
        "\n",
        "class FusionProjection(nn.Module):\n",
        "    def __init__(self, in_dim, proj_dim=128):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(nn.Linear(in_dim, proj_dim), nn.ReLU(), nn.Linear(proj_dim, proj_dim))\n",
        "    def forward(self, x): return self.mlp(x)"
      ],
      "metadata": {
        "id": "D65HMHM0NEqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nt_xent_loss(z1, z2, temperature=0.5):\n",
        "    z1 = nn.functional.normalize(z1, dim=1)\n",
        "    z2 = nn.functional.normalize(z2, dim=1)\n",
        "    B = z1.shape[0]\n",
        "    z = torch.cat([z1,z2], dim=0)\n",
        "    sim = torch.matmul(z, z.T) / temperature\n",
        "    mask = (~torch.eye(2*B, dtype=torch.bool, device=sim.device)).float()\n",
        "    exp_sim = torch.exp(sim) * mask\n",
        "    positives = torch.exp((z1*z2).sum(dim=1)/temperature)\n",
        "    positives = torch.cat([positives, positives], dim=0)\n",
        "    denom = exp_sim.sum(dim=1)\n",
        "    loss = -torch.log(positives / (denom + 1e-12))\n",
        "    return loss.mean()"
      ],
      "metadata": {
        "id": "dqzRpLFQNHj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveDPMultimodalClient(fl.client.NumPyClient):\n",
        "    def __init__(self, graph_enc, ts_enc, fusion, client_data, device=\"cpu\",\n",
        "                 local_epochs=1, local_steps=100, batch_size=16, lr=1e-3):\n",
        "        self.device = torch.device(device)\n",
        "        self.graph_enc = graph_enc.to(self.device)\n",
        "        self.ts_enc = ts_enc.to(self.device)\n",
        "        self.fusion = fusion.to(self.device)\n",
        "\n",
        "        self.client_data = client_data  # dict with 'graph' (pyg.Data), 'ts' (Tensor NxL), optional 'images' (Tensor)\n",
        "        self.local_epochs = local_epochs\n",
        "        self.local_steps = local_steps\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "\n",
        "    def get_parameters(self, config=None):\n",
        "        params = []\n",
        "        for model in (self.graph_enc, self.ts_enc, self.fusion):\n",
        "            for _, v in model.state_dict().items():\n",
        "                params.append(v.detach().cpu().numpy())\n",
        "        return params\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        it = iter(parameters)\n",
        "        for model in (self.graph_enc, self.ts_enc, self.fusion):\n",
        "            sd = model.state_dict()\n",
        "            new_sd = {}\n",
        "            for k in sd.keys():\n",
        "                arr = next(it)\n",
        "                new_sd[k] = torch.tensor(arr, dtype=sd[k].dtype)\n",
        "            model.load_state_dict(new_sd)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # 1) load server params\n",
        "        if parameters is not None:\n",
        "            try:\n",
        "                self.set_parameters(parameters)\n",
        "            except Exception as e:\n",
        "                print(\"set_parameters failed:\", e)\n",
        "\n",
        "        # 2) build combined dataset and DataLoader (yields single-sample tuples)\n",
        "        graph = self.client_data.get(\"graph\", None)\n",
        "        ts = self.client_data.get(\"ts\", None)\n",
        "        images = self.client_data.get(\"images\", None)\n",
        "        # choose dataset length: min available or explicit\n",
        "        N = min(\n",
        "            (images.shape[0] if images is not None else float('inf'),\n",
        "             ts.shape[0] if ts is not None else float('inf'),\n",
        "             graph.x.shape[0] if graph is not None else float('inf'))\n",
        "        )\n",
        "        N = int(N if N != float('inf') else (ts.shape[0] if ts is not None else 0))\n",
        "        ds = MultimodalDataset(graph, ts, images, N=N)\n",
        "        loader = DataLoader(ds, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        # 3) compute per-modality adaptive noise from single sample batch\n",
        "        sample_img, sample_node_idx, sample_ts = next(iter(loader))\n",
        "        # convert to typical tensor shapes expected by helpers\n",
        "        n_img = noise_for_image_batch(sample_img) if images is not None else None\n",
        "        n_graph = noise_for_graph(graph, node_idx=sample_node_idx) if graph is not None else None\n",
        "        n_ts = noise_for_ts_batch(sample_ts) if ts is not None else None\n",
        "\n",
        "        noise_multiplier = combine_noise(n_img, n_graph, n_ts, strategy=\"max\")\n",
        "        print(f\"[Client] adaptive noise multipliers: img={n_img}, graph={n_graph}, ts={n_ts} -> combined={noise_multiplier}\")\n",
        "\n",
        "        # 4) Prepare a single optimizer over all params (we do DP over the whole multimodal model)\n",
        "        all_params = list(self.graph_enc.parameters()) + list(self.ts_enc.parameters()) + list(self.fusion.parameters())\n",
        "        optimizer = optim.Adam(all_params, lr=self.lr)\n",
        "\n",
        "        # 5) Attach PrivacyEngine\n",
        "        privacy_engine = PrivacyEngine()\n",
        "        # IMPORTANT: make_private expects the dataloader to yield single samples; our loader does.\n",
        "        model_wrapper = nn.Sequential()  # dummy wrapper; Opacus registers module parameters, so it's OK to pass a wrapper with submodules if needed\n",
        "        # Instead of wrapper, we pass nothing special; we still call make_private with module=self.graph_enc (only for bookkeeping).\n",
        "        # To be safe, pass an nn.Module that contains all params:\n",
        "        class _All(nn.Module):\n",
        "            def __init__(self, graph_enc, ts_enc, fusion):\n",
        "                super().__init__()\n",
        "                self.graph_enc = graph_enc\n",
        "                self.ts_enc = ts_enc\n",
        "                self.fusion = fusion\n",
        "        combined_module = _All(self.graph_enc, self.ts_enc, self.fusion)\n",
        "\n",
        "        combined_module, optimizer, private_loader = privacy_engine.make_private(\n",
        "            module=combined_module,\n",
        "            optimizer=optimizer,\n",
        "            data_loader=loader,\n",
        "            noise_multiplier=noise_multiplier,\n",
        "            max_grad_norm=1.0,\n",
        "        )\n",
        "\n",
        "        # 6) local training loop (DP-SGD)\n",
        "        combined_module.train()\n",
        "        step = 0\n",
        "        last_loss = 0.0\n",
        "        for epoch in range(self.local_epochs):\n",
        "            for batch in private_loader:\n",
        "                img_batch, node_idx_batch, ts_batch = batch\n",
        "                # move to device\n",
        "                ts_batch = ts_batch.to(self.device).float()\n",
        "                # graph: gather node features for batch (simple example: per-node features)\n",
        "                node_idx_batch = node_idx_batch.to(self.device)\n",
        "                x_nodes = graph.x[node_idx_batch].to(self.device).float() if graph is not None else torch.zeros((ts_batch.size(0),1)).to(self.device)\n",
        "                # image: pass if provided\n",
        "                img_tensor = img_batch.to(self.device).float() if images is not None else torch.zeros((ts_batch.size(0),1)).to(self.device)\n",
        "\n",
        "                # create two augmentations per modality (simple jitter/mask examples)\n",
        "                # For brevity, do basic augmentations:\n",
        "                ts_v1 = ts_batch + 0.01*torch.randn_like(ts_batch)\n",
        "                ts_v2 = ts_batch + 0.02*torch.randn_like(ts_batch)\n",
        "                x1 = x_nodes * (torch.rand_like(x_nodes) > 0.1).float()\n",
        "                x2 = x_nodes * (torch.rand_like(x_nodes) > 0.15).float()\n",
        "\n",
        "                # encode\n",
        "                z_g1 = self.graph_enc(x1)\n",
        "                z_g2 = self.graph_enc(x2)\n",
        "                z_t1 = self.ts_enc(ts_v1)\n",
        "                z_t2 = self.ts_enc(ts_v2)\n",
        "\n",
        "                # fuse (concatenate per-sample)\n",
        "                fused1 = torch.cat([z_g1, z_t1], dim=1)\n",
        "                fused2 = torch.cat([z_g2, z_t2], dim=1)\n",
        "                z_f1 = self.fusion(fused1)\n",
        "                z_f2 = self.fusion(fused2)\n",
        "\n",
        "                loss = nt_xent_loss(z_f1, z_f2)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                last_loss = loss.item()\n",
        "                step += 1\n",
        "                if step >= self.local_steps:\n",
        "                    break\n",
        "            if step >= self.local_steps:\n",
        "                break\n",
        "\n",
        "        # 7) after training get epsilon (delta chosen as typical 1e-5)\n",
        "        try:\n",
        "            epsilon = privacy_engine.get_epsilon(delta=1e-5)\n",
        "        except Exception as e:\n",
        "            # fallback if not supported\n",
        "            epsilon = None\n",
        "            print(\"Could not compute epsilon:\", e)\n",
        "\n",
        "        # 8) return updated params + sample count + metrics\n",
        "        params = []\n",
        "        for model in (self.graph_enc, self.ts_enc, self.fusion):\n",
        "            for _, v in model.state_dict().items():\n",
        "                params.append(v.detach().cpu().numpy())\n",
        "        num_examples = len(loader.dataset)\n",
        "        metrics = {\"loss\": float(last_loss)}\n",
        "        if epsilon is not None:\n",
        "            metrics[\"epsilon\"] = float(epsilon)\n",
        "        return params, num_examples, metrics\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        return 0.0, 0, {}"
      ],
      "metadata": {
        "id": "S-EILoK2NKEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from opacus import PrivacyEngine\n",
        "from scipy.stats import entropy"
      ],
      "metadata": {
        "id": "w7m-ZJxufiik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dataset_entropy_numpy(dataset_tensor):\n",
        "    \"\"\"\n",
        "    Compute an entropy-like score for a dataset tensor.\n",
        "    Accepts: numpy array or torch tensor of shape (N, ...).\n",
        "    Returns: scalar >0. Larger => more \"complex\" -> adjust noise lower (example).\n",
        "    \"\"\"\n",
        "    if isinstance(dataset_tensor, torch.Tensor):\n",
        "        arr = dataset_tensor.detach().cpu().numpy().ravel()\n",
        "    else:\n",
        "        arr = np.asarray(dataset_tensor).ravel()\n",
        "    # Normalize to histogram\n",
        "    if arr.size == 0:\n",
        "        return 0.0\n",
        "    # Use 256 bins (clamped)\n",
        "    hist, _ = np.histogram(arr, bins=256, density=True)\n",
        "    # Add small eps to avoid zeros\n",
        "    hist = hist + 1e-12\n",
        "    return float(entropy(hist))"
      ],
      "metadata": {
        "id": "FkL8vw0CXha3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_adaptive_noise_multiplier(entropy_score, base_noise=1.0, min_noise=0.3, max_noise=5.0, sensitivity=1.0):\n",
        "    \"\"\"\n",
        "    Map entropy_score -> noise_multiplier.\n",
        "    Heuristic: higher entropy -> dataset more informative -> use lower noise (improve utility).\n",
        "    Lower entropy -> add more noise to preserve privacy.\n",
        "    This mapping is tunable.\n",
        "    \"\"\"\n",
        "    # Sigmoid-like mapping: invert entropy to make higher entropy -> lower noise\n",
        "    # First normalize entropy_score to [0,1] using a soft scale\n",
        "    scale = 1.0 / (1.0 + math.exp(- (entropy_score - 4.0)))  # center ~4.0; adjust if needed\n",
        "    # inverted\n",
        "    inv = 1.0 - scale\n",
        "    noise = base_noise * (min_noise + (max_noise - min_noise) * inv)\n",
        "    # ensure bounds\n",
        "    noise = max(min_noise, min(max_noise, float(noise)))\n",
        "    return noise"
      ],
      "metadata": {
        "id": "5uISRw-QXj1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveDPPrivCLClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model: nn.Module, trainloader, device='cpu',\n",
        "                 lr=0.01, epochs=1, base_noise=1.0, max_grad_norm=1.0):\n",
        "        self.model = model.to(device)\n",
        "        self.trainloader = trainloader\n",
        "        self.device = device\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.base_noise = base_noise\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "\n",
        "        # optimizer (will be wrapped by Opacus when making private)\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr)\n",
        "        # placeholder for privacy engine; will be attached during fit with computed noise\n",
        "        self.privacy_engine = None\n",
        "        self.criterion = nn.CrossEntropyLoss()  # replace with NT-Xent or contrastive loss as required\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters_list):\n",
        "        params = {k: torch.tensor(v) for k, v in zip(self.model.state_dict().keys(), parameters_list)}\n",
        "        self.model.load_state_dict(params)\n",
        "\n",
        "    def _compute_client_entropy(self):\n",
        "        # Sample a subset (or entire) dataset to compute entropy. Keep lightweight.\n",
        "        # Assumes trainloader yields (x, y) or (x1, x2, y) tuples. We'll flatten inputs.\n",
        "        sample_tensors = []\n",
        "        max_samples = 512  # cap for speed\n",
        "        taken = 0\n",
        "        for batch in self.trainloader:\n",
        "            x = batch[0]\n",
        "            if isinstance(x, (list, tuple)):\n",
        "                x = x[0]\n",
        "            sample_tensors.append(x.detach().cpu())\n",
        "            taken += x.shape[0]\n",
        "            if taken >= max_samples:\n",
        "                break\n",
        "        if len(sample_tensors) == 0:\n",
        "            return 0.0\n",
        "        cat = torch.cat(sample_tensors, dim=0)\n",
        "        # compute entropy on flattened values\n",
        "        return compute_dataset_entropy_numpy(cat)\n",
        "    def fit(self, parameters, config):\n",
        "        # Set model weights from server\n",
        "        if parameters is not None:\n",
        "            self.set_parameters(parameters)\n",
        "\n",
        "        # Compute client-specific noise multiplier\n",
        "        entropy_score = self._compute_client_entropy()\n",
        "        noise_multiplier = compute_adaptive_noise_multiplier(entropy_score, base_noise=self.base_noise)\n",
        "\n",
        "        # Recreate optimizer\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr)\n",
        "\n",
        "        # Detach any previous privacy engine\n",
        "        if self.privacy_engine is not None:\n",
        "            try:\n",
        "                self.privacy_engine.detach()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Explicit sample rate\n",
        "        batch_size = self.trainloader.batch_size\n",
        "        dataset_size = len(self.trainloader.dataset)\n",
        "        sample_rate = batch_size / dataset_size\n",
        "        delta = 1.0 / dataset_size  # standard choice\n",
        "\n",
        "        # Reinitialize PrivacyEngine with accountant\n",
        "        self.privacy_engine = PrivacyEngine(accountant=\"rdp\")  # force RDP accountant\n",
        "        self.model, self.optimizer, self.trainloader = self.privacy_engine.make_private(\n",
        "            module=self.model,\n",
        "            optimizer=self.optimizer,\n",
        "            data_loader=self.trainloader,\n",
        "            noise_multiplier=noise_multiplier,\n",
        "            max_grad_norm=self.max_grad_norm,\n",
        "            poisson_sampling=False,  # we’re using uniform sampling\n",
        "        )\n",
        "\n",
        "        # Local training loop\n",
        "        self.model.train()\n",
        "        for epoch in range(self.epochs):\n",
        "            for batch in self.trainloader:\n",
        "                if isinstance(batch, (list, tuple)) and len(batch) >= 2:\n",
        "                    x = batch[0].to(self.device)\n",
        "                    if len(batch) >= 2 and isinstance(batch[1], torch.Tensor) and batch[1].dim() == x.dim():\n",
        "                        x2 = batch[1].to(self.device)\n",
        "                        z1 = self.model(x)\n",
        "                        z2 = self.model(x2)\n",
        "                        loss = nn.functional.mse_loss(z1, z2)\n",
        "                    else:\n",
        "                        inputs = x\n",
        "                        targets = batch[1].to(self.device) if len(batch) > 1 else None\n",
        "                        outputs = self.model(inputs)\n",
        "                        loss = self.criterion(outputs, targets) if targets is not None else torch.tensor(0.0, device=self.device)\n",
        "                else:\n",
        "                    inputs = batch.to(self.device)\n",
        "                    outputs = self.model(inputs)\n",
        "                    loss = torch.tensor(0.0, device=self.device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "        # Compute epsilon after training\n",
        "        try:\n",
        "            epsilon, best_alpha = self.privacy_engine.accountant.get_epsilon(delta)\n",
        "        except Exception:\n",
        "            epsilon, best_alpha = None, None\n",
        "\n",
        "        # Log results\n",
        "        print(f\"[Client] noise_multiplier={noise_multiplier:.3f}, epsilon={epsilon}, delta={delta}\")\n",
        "\n",
        "        # Return updated params to server\n",
        "        new_params = self.get_parameters({})\n",
        "        return new_params, len(self.trainloader.dataset), {\"noise_multiplier\": noise_multiplier, \"epsilon\": epsilon}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        # Set model and run local eval (simple)\n",
        "        if parameters is not None:\n",
        "            self.set_parameters(parameters)\n",
        "        self.model.eval()\n",
        "        loss_total = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in self.trainloader:\n",
        "                if isinstance(batch, (list, tuple)):\n",
        "                    x = batch[0].to(self.device)\n",
        "                    y = batch[1].to(self.device) if len(batch) > 1 else None\n",
        "                else:\n",
        "                    x = batch.to(self.device)\n",
        "                    y = None\n",
        "                outputs = self.model(x)\n",
        "                if y is not None:\n",
        "                    loss_total += nn.functional.cross_entropy(outputs, y, reduction=\"sum\").item()\n",
        "                    preds = outputs.argmax(dim=1)\n",
        "                    correct += (preds == y).sum().item()\n",
        "                    total += y.size(0)\n",
        "        if total == 0:\n",
        "            return 0.0, 0, {}\n",
        "        loss_avg = loss_total / total\n",
        "        accuracy = correct / total\n",
        "        return float(loss_avg), total, {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "pvvjz-KVXomM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_adaptive_dp_client(model_class, trainloader, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Quick test of AdaptiveDPPrivCLClient.\n",
        "    Trains for 1 epoch with adaptive DP-SGD and prints noise multiplier & epsilon.\n",
        "    Accepts model_class (e.g., SmallNet) and instantiates it inside.\n",
        "    \"\"\"\n",
        "    # Create a new model instance for each test run\n",
        "    model = model_class().to(device)\n",
        "\n",
        "    client = AdaptiveDPPrivCLClient(\n",
        "        model=model,\n",
        "        trainloader=trainloader,\n",
        "        device=device,\n",
        "        lr=0.01,\n",
        "        epochs=1,\n",
        "        base_noise=1.0,\n",
        "        max_grad_norm=1.0,\n",
        "    )\n",
        "\n",
        "    # Run one fit round\n",
        "    params, num_examples, metrics = client.fit(parameters=None, config={})\n",
        "    print(\"Client trained with:\")\n",
        "    print(f\"  - Noise multiplier: {metrics.get('noise_multiplier')}\")\n",
        "    print(f\"  - Epsilon: {metrics.get('epsilon')}\")\n",
        "    print(f\"  - Examples seen: {num_examples}\")\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "lA7ZxxYaXpkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose you already have a simple model & DataLoader\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Simple model\n",
        "class SmallNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(28*28, 10)\n",
        "    def forward(self, x):\n",
        "        return self.fc(x.view(x.size(0), -1))\n",
        "\n",
        "# Dataset\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "mnist = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "# Larger subset for testing epsilon\n",
        "subset = Subset(mnist, range(50000))   # instead of 200\n",
        "trainloader = DataLoader(subset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Train longer\n",
        "metrics = test_adaptive_dp_client(SmallNet, trainloader, device=\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7T4TT16YTal",
        "outputId": "dd2291b4-6408-412b-ac25-9fd044b264e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 39.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.00MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.22MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.4MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-1979534545.py:102: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Client] noise_multiplier=4.688, epsilon=None, delta=2e-05\n",
            "Client trained with:\n",
            "  - Noise multiplier: 4.688039162171171\n",
            "  - Epsilon: None\n",
            "  - Examples seen: 50000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tenseal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmOpxhBqfxXt",
        "outputId": "9e37416b-b565-4af9-ca2d-fa5c4e327705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tenseal\n",
            "  Downloading tenseal-0.3.16-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Downloading tenseal-0.3.16-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/4.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3.6/4.8 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenseal\n",
            "Successfully installed tenseal-0.3.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading, time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "import flwr as fl\n",
        "import tenseal as ts"
      ],
      "metadata": {
        "id": "6wEkoKKlibdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tenseal_context():\n",
        "    ctx = ts.context(\n",
        "        ts.SCHEME_TYPE.CKKS,\n",
        "        poly_modulus_degree=8192,\n",
        "        coeff_mod_bit_sizes=[60, 40, 40, 60],\n",
        "    )\n",
        "    ctx.global_scale = 2**40\n",
        "    ctx.generate_galois_keys()\n",
        "    public_bytes = ctx.serialize(save_secret_key=False)\n",
        "    return ctx, public_bytes"
      ],
      "metadata": {
        "id": "ZjnWhe1wikP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def params_to_numpy_list(state_dict):\n",
        "    return [v.cpu().numpy().astype(np.float64) for _, v in state_dict.items()]"
      ],
      "metadata": {
        "id": "BWqUBsPVim0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _params_to_flat_lists(param_list):\n",
        "    arrays, shapes = [], []\n",
        "    for a in param_list:\n",
        "        arr = np.asarray(a, dtype=np.float64)\n",
        "        shapes.append(arr.shape)\n",
        "        arrays.append(arr.ravel().tolist())\n",
        "    return arrays, shapes"
      ],
      "metadata": {
        "id": "npKsx9Toiovw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _flat_lists_to_param_arrays(flat_lists, shapes):\n",
        "    out = []\n",
        "    for flat, shape in zip(flat_lists, shapes):\n",
        "        arr = np.asarray(flat, dtype=np.float64).reshape(shape)\n",
        "        out.append(arr)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "TRhuAfb7iqul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encrypt_params_with_public_ctx(params_numpy_list, public_ctx_bytes):\n",
        "    client_ctx = ts.context_from(public_ctx_bytes)\n",
        "    encrypted_serialized, shapes = [], []\n",
        "    for arr in params_numpy_list:\n",
        "        flat = arr.ravel().tolist()\n",
        "        ck = ts.ckks_vector(client_ctx, flat)\n",
        "        encrypted_serialized.append(ck.serialize())\n",
        "        shapes.append(arr.shape)\n",
        "    return encrypted_serialized, shapes"
      ],
      "metadata": {
        "id": "In2fifDYis8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deserialize_and_aggregate_encrypted(all_clients_serialized, server_ctx, shapes):\n",
        "    num_clients = len(all_clients_serialized)\n",
        "    aggregated_flat_lists = []\n",
        "    for param_idx in range(len(shapes)):\n",
        "        sum_cipher = None\n",
        "        for client_serialized in all_clients_serialized:\n",
        "            ck = ts.ckks_vector_from(server_ctx, client_serialized[param_idx])\n",
        "            if sum_cipher is None:\n",
        "                sum_cipher = ck\n",
        "            else:\n",
        "                sum_cipher += ck\n",
        "        avg_cipher = sum_cipher * (1.0 / float(num_clients))\n",
        "        decrypted = avg_cipher.decrypt()\n",
        "        aggregated_flat_lists.append(decrypted)\n",
        "    aggregated_params = _flat_lists_to_param_arrays(aggregated_flat_lists, shapes)\n",
        "    return aggregated_params"
      ],
      "metadata": {
        "id": "59jjQPZaiwYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageNet(nn.Module):  # for MNIST\n",
        "    def __init__(self, out=10):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, out),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "GItPV9CSizJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n"
      ],
      "metadata": {
        "id": "PMxryQxxi09I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphNet(nn.Module):  # for Cora\n",
        "    def __init__(self, in_feats, hidden=64, out=7):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_feats, hidden)\n",
        "        self.conv2 = GCNConv(hidden, out)\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        return self.conv2(x, edge_index)"
      ],
      "metadata": {
        "id": "xxQZJeC2i3QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeNet(nn.Module):  # simple RNN for time series\n",
        "    def __init__(self, in_dim=1, hidden=32, out=5):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(in_dim, hidden, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden, out)\n",
        "    def forward(self, x):\n",
        "        _, h = self.rnn(x)\n",
        "        return self.fc(h.squeeze(0))"
      ],
      "metadata": {
        "id": "-_X-leX2i5sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HEClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, train_loader, public_ctx_bytes, is_graph=False, device=\"cpu\"):\n",
        "        self.model = model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.device = device\n",
        "        self.public_ctx_bytes = public_ctx_bytes\n",
        "        self.is_graph = is_graph\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters_list):\n",
        "        params = {k: torch.tensor(v) for k, v in zip(self.model.state_dict().keys(), parameters_list)}\n",
        "        self.model.load_state_dict(params)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        if parameters is not None:\n",
        "            self.set_parameters(parameters)\n",
        "        opt = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.model.train()\n",
        "        for batch in self.train_loader:\n",
        "            opt.zero_grad()\n",
        "            if self.is_graph:\n",
        "                data = batch.to(self.device)\n",
        "                out = self.model(data)\n",
        "                loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
        "            else:\n",
        "                x, y = batch\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                out = self.model(x)\n",
        "                loss = loss_fn(out, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        params_numpy = params_to_numpy_list(self.model.state_dict())\n",
        "        encrypted_serialized, shapes = encrypt_params_with_public_ctx(params_numpy, self.public_ctx_bytes)\n",
        "        return None, len(self.train_loader.dataset), {\"enc_params\": encrypted_serialized, \"shapes\": shapes}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        if parameters is not None:\n",
        "            self.set_parameters(parameters)\n",
        "        return 0.0, len(self.train_loader.dataset), {}"
      ],
      "metadata": {
        "id": "I1z6YNoki8uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SecureHEFedAvg(fl.server.strategy.FedAvg):\n",
        "    def __init__(self, server_tenseal_ctx, param_shapes, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.server_ctx = server_tenseal_ctx\n",
        "        self.param_shapes = param_shapes\n",
        "        self.parameters = None\n",
        "\n",
        "    def aggregate_fit(self, server_round, results, failures):\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        all_clients_serialized = []\n",
        "        for _, fit_res in results:\n",
        "            client_return = fit_res[1]\n",
        "            if isinstance(client_return, dict):\n",
        "                enc_list = client_return[\"enc_params\"]\n",
        "                shapes = client_return.get(\"shapes\", self.param_shapes)\n",
        "            else:\n",
        "                enc_list, shapes = client_return\n",
        "            all_clients_serialized.append(enc_list)\n",
        "        averaged_params = deserialize_and_aggregate_encrypted(all_clients_serialized, self.server_ctx, self.param_shapes)\n",
        "        self.parameters = averaged_params\n",
        "        return averaged_params, {}"
      ],
      "metadata": {
        "id": "oQEJNAZwi_pq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWrOvdhMdd+GQ+HPfqORDL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}